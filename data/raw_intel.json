{
  "generated_at": "2026-01-09T18:57:38.172667",
  "total_items": 283,
  "category_counts": {
    "vertical_grain": 1,
    "deep_dive": 282,
    "headline": 0,
    "tools": 0,
    "bright_spot": 0
  },
  "articles": [
    {
      "title": "Need automated, accurate grain grading in minutes?",
      "link": "https://groundtruth.ag#benchtopmvnirs",
      "summary": "",
      "published": "2026-01-09T18:57:33.156393",
      "source": "Ground Truth Ag",
      "category": "vertical_grain"
    },
    {
      "title": "Mastering the Game of Go with Self-play Experience Replay",
      "link": "https://arxiv.org/abs/2601.03306",
      "summary": "arXiv:2601.03306v1 Announce Type: new \nAbstract: The game of Go has long served as a benchmark for artificial intelligence, demanding sophisticated strategic reasoning and long-term planning. Previous approaches such as AlphaGo and its successors, have predominantly relied on model-based Monte-Carlo Tree Search (MCTS). In this work, we present QZero, a novel model-free reinforcement learning algorithm that forgoes search during training and learns a Nash equilibrium policy through self-play and ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Digital Red Queen: Adversarial Program Evolution in Core War with LLMs",
      "link": "https://arxiv.org/abs/2601.03335",
      "summary": "arXiv:2601.03335v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adversarial dynamics that characterize real-world evolutionary processes. Here, we study Digital Red Queen (DRQ), a simple self-play algorithm that embrace",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization",
      "link": "https://arxiv.org/abs/2601.03359",
      "summary": "arXiv:2601.03359v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing the description of the primary task an LLM has to perform, neglecting the granular constraints that function as acceptance criteria for its response. We propose a novel multi-agentic workflow that de",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Exploration Through Introspection: A Self-Aware Reward Model",
      "link": "https://arxiv.org/abs/2601.03389",
      "summary": "arXiv:2601.03389v1 Announce Type: new \nAbstract: Understanding how artificial agents model internal mental states is central to advancing Theory of Mind in AI. Evidence points to a unified system for self- and other-awareness. We explore this self-awareness by having reinforcement learning agents infer their own internal states in gridworld environments. Specifically, we introduce an introspective exploration component that is inspired by biological pain as a learning signal by utilizing a hidde",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms",
      "link": "https://arxiv.org/abs/2601.03470",
      "summary": "arXiv:2601.03470v2 Announce Type: new \nAbstract: We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigating multi-objective trade-offs inherent in trustworthiness evaluation. We demonstrate this approach using uncertainty quantification as an exemplar measurement mechanism and illustrate feasibility thr",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CPGPrompt: Translating Clinical Guidelines into LLM-Executable Decision Support",
      "link": "https://arxiv.org/abs/2601.03475",
      "summary": "arXiv:2601.03475v1 Announce Type: new \nAbstract: Clinical practice guidelines (CPGs) provide evidence-based recommendations for patient care; however, integrating them into Artificial Intelligence (AI) remains challenging. Previous approaches, such as rule-based systems, face significant limitations, including poor interpretability, inconsistent adherence to guidelines, and narrow domain applicability. To address this, we develop and validate CPGPrompt, an auto-prompting system that converts nar",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Personalization of Large Foundation Models for Health Interventions",
      "link": "https://arxiv.org/abs/2601.03482",
      "summary": "arXiv:2601.03482v1 Announce Type: new \nAbstract: Large foundation models (LFMs) transform healthcare AI in prevention, diagnostics, and treatment. However, whether LFMs can provide truly personalized treatment recommendations remains an open question. Recent research has revealed multiple challenges for personalization, including the fundamental generalizability paradox: models achieving high accuracy in one clinical study perform at chance level in others, demonstrating that personalization and",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Evolving Programmatic Skill Networks",
      "link": "https://arxiv.org/abs/2601.03509",
      "summary": "arXiv:2601.03509v1 Announce Type: new \nAbstract: We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault loc",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Variance Computation for Weighted Model Counting with Knowledge Compilation Approach",
      "link": "https://arxiv.org/abs/2601.03523",
      "summary": "arXiv:2601.03523v1 Announce Type: new \nAbstract: One of the most important queries in knowledge compilation is weighted model counting (WMC), which has been applied to probabilistic inference on various models, such as Bayesian networks. In practical situations on inference tasks, the model's parameters have uncertainty because they are often learned from data, and thus we want to compute the degree of uncertainty in the inference outcome. One possible approach is to regard the inference outcome",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules",
      "link": "https://arxiv.org/abs/2601.03537",
      "summary": "arXiv:2601.03537v1 Announce Type: new \nAbstract: Defending against jailbreak attacks is crucial for the safe deployment of Large Language Models (LLMs). Recent research has attempted to improve safety by training models to reason over safety rules before responding. However, a key issue lies in determining what form of safety reasoning effectively defends against jailbreak attacks, which is difficult to explicitly design or directly obtain. To address this, we propose \\textbf{STAR-S} (\\textbf{S}",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ReEfBench: Quantifying the Reasoning Efficiency of LLMs",
      "link": "https://arxiv.org/abs/2601.03550",
      "summary": "arXiv:2601.03550v1 Announce Type: new \nAbstract: Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes an",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models",
      "link": "https://arxiv.org/abs/2601.03555",
      "summary": "arXiv:2601.03555v1 Announce Type: new \nAbstract: Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Controllable LLM Reasoning via Sparse Autoencoder-Based Steering",
      "link": "https://arxiv.org/abs/2601.03595",
      "summary": "arXiv:2601.03595v1 Announce Type: new \nAbstract: Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous selection often produces inefficient or even erroneous reasoning paths. To make reasoning more reliable and flexible, it is important to develop method",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Interleaved Tool-Call Reasoning for Protein Function Understanding",
      "link": "https://arxiv.org/abs/2601.03604",
      "summary": "arXiv:2601.03604v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have highlighted the effectiveness of chain-of-thought reasoning in symbolic domains such as mathematics and programming. However, our study shows that directly transferring such text-based reasoning paradigms to protein function understanding is ineffective: reinforcement learning mainly amplifies superficial keyword patterns while failing to introduce new biological knowledge, resulting in limited ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Architecting Agentic Communities using Design Patterns",
      "link": "https://arxiv.org/abs/2601.03624",
      "summary": "arXiv:2601.03624v1 Announce Type: new \nAbstract: The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Ag",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs",
      "link": "https://arxiv.org/abs/2601.03662",
      "summary": "arXiv:2601.03662v1 Announce Type: new \nAbstract: Large Reasoning Models (LRMs) achieve remarkable success through explicit thinking steps, yet the thinking steps introduce a novel risk by potentially amplifying unsafe behaviors. Despite this vulnerability, conventional defense mechanisms remain ineffective as they overlook the unique reasoning dynamics of LRMs. In this work, we find that the emergence of safe-reminding phrases within thinking steps plays a pivotal role in ensuring LRM safety. Mo",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction",
      "link": "https://arxiv.org/abs/2601.03672",
      "summary": "arXiv:2601.03672v1 Announce Type: new \nAbstract: Query correction is a critical entry point in modern search pipelines, demanding high accuracy strictly within real-time latency constraints. Chain-of-Thought (CoT) reasoning improves accuracy but incurs prohibitive latency for real-time query correction. A potential solution is to output an answer before reasoning to reduce latency; however, under autoregressive decoding, the early answer is independent of subsequent reasoning, preventing the mod",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Personalized Medication Planning via Direct Domain Modeling and LLM-Generated Heuristics",
      "link": "https://arxiv.org/abs/2601.03687",
      "summary": "arXiv:2601.03687v1 Announce Type: new \nAbstract: Personalized medication planning involves selecting medications and determining a dosing schedule to achieve medical goals specific to each individual patient. Previous work successfully demonstrated that automated planners, using general domain-independent heuristics, are able to generate personalized treatments, when the domain and problems are modeled using a general domain description language (\\pddlp). Unfortunately, this process was limited ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation",
      "link": "https://arxiv.org/abs/2601.03769",
      "summary": "arXiv:2601.03769v2 Announce Type: new \nAbstract: Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the \"answer right but reasoning wrong\" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition",
      "link": "https://arxiv.org/abs/2601.03822",
      "summary": "arXiv:2601.03822v1 Announce Type: new \nAbstract: Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Defeasible Conditionals using Answer Set Programming",
      "link": "https://arxiv.org/abs/2601.03840",
      "summary": "arXiv:2601.03840v1 Announce Type: new \nAbstract: Defeasible entailment is concerned with drawing plausible conclusions from incomplete information. A foundational framework for modelling defeasible entailment is the KLM framework. Introduced by Kraus, Lehmann, and Magidor, the KLM framework outlines several key properties for defeasible entailment. One of the most prominent algorithms within this framework is Rational Closure (RC). This paper presents a declarative definition for computing RC us",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "XAI-LAW: A Logic Programming Tool for Modeling, Explaining, and Learning Legal Decisions",
      "link": "https://arxiv.org/abs/2601.03844",
      "summary": "arXiv:2601.03844v1 Announce Type: new \nAbstract: We propose an approach to model articles of the Italian Criminal Code (ICC), using Answer Set Programming (ASP), and to semi-automatically learn legal rules from examples based on prior judicial decisions. The developed tool is intended to support legal experts during the criminal trial phase by providing reasoning and possible legal outcomes. The methodology involves analyzing and encoding articles of the ICC in ASP, including \"crimes against the",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Formally Explaining Decision Tree Models with Answer Set Programming",
      "link": "https://arxiv.org/abs/2601.03845",
      "summary": "arXiv:2601.03845v1 Announce Type: new \nAbstract: Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techni",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming",
      "link": "https://arxiv.org/abs/2601.03847",
      "summary": "arXiv:2601.03847v1 Announce Type: new \nAbstract: Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their \"black-box\" nature. xAI approaches can be characterized along different dimensions such as their scope (global versus local explanations) or underlying methodologies (statistic-based ver",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Investigating the Grounding Bottleneck for a Large-Scale Configuration Problem: Existing Tools and Constraint-Aware Guessing",
      "link": "https://arxiv.org/abs/2601.03850",
      "summary": "arXiv:2601.03850v1 Announce Type: new \nAbstract: Answer set programming (ASP) aims to realize the AI vision: The user specifies the problem, and the computer solves it. Indeed, ASP has made this vision true in many application domains. However, will current ASP solving techniques scale up for large configuration problems? As a benchmark for such problems, we investigated the configuration of electronic systems, which may comprise more than 30,000 components. We show the potential and limits of c",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Current Agents Fail to Leverage World Model as Tool for Foresight",
      "link": "https://arxiv.org/abs/2601.03905",
      "summary": "arXiv:2601.03905v2 Announce Type: new \nAbstract: Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answe",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification",
      "link": "https://arxiv.org/abs/2601.03948",
      "summary": "arXiv:2601.03948v2 Announce Type: new \nAbstract: Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards are verifiable but inherently noisy, causing standard RL to degenerate into reward hacking. To address this, we propose Trade-R1, a model training fra",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models",
      "link": "https://arxiv.org/abs/2601.03969",
      "summary": "arXiv:2601.03969v1 Announce Type: new \nAbstract: Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthink",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MobileDreamer: Generative Sketch World Model for GUI Agent",
      "link": "https://arxiv.org/abs/2601.04035",
      "summary": "arXiv:2601.04035v1 Announce Type: new \nAbstract: Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-actio",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows",
      "link": "https://arxiv.org/abs/2601.04060",
      "summary": "arXiv:2601.04060v1 Announce Type: new \nAbstract: AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions",
      "link": "https://arxiv.org/abs/2601.04170",
      "summary": "arXiv:2601.04170v1 Announce Type: new \nAbstract: Multi-agent Large Language Model (LLM) systems have emerged as powerful architectures for complex task decomposition and collaborative problem-solving. However, their long-term behavioral stability remains largely unexamined. This study introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences. We present a comprehensive theoretic",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "DeepResearch-Slice: Bridging the Retrieval-Utilization Gap via Explicit Text Slicing",
      "link": "https://arxiv.org/abs/2601.03261",
      "summary": "arXiv:2601.03261v1 Announce Type: cross \nAbstract: Deep Research agents predominantly optimize search policies to maximize retrieval probability. However, we identify a critical bottleneck: the retrieval-utilization gap, where models fail to use gold evidence even after it is retrieved, due to context blindness in noisy environments. To bridge this gap, we propose DeepResearch-Slice, a simple yet effective neuro-symbolic framework. Unlike implicit attention, our approach predicts precise span in",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Internal Reasoning vs. External Control: A Thermodynamic Analysis of Sycophancy in Large Language Models",
      "link": "https://arxiv.org/abs/2601.03263",
      "summary": "arXiv:2601.03263v2 Announce Type: cross \nAbstract: Large Language Models exhibit sycophancy: prioritizing agreeableness over correctness. Current remedies evaluate reasoning outcomes: RLHF rewards correct answers, self-correction critiques outputs. All require ground truth, which is often unavailable at inference time and vulnerable to the same biases. We explore evaluating the reasoning process instead. Regulated Causal Anchoring (RCA) verifies whether outputs follow from their reasoning traces",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Benchmarking and Adapting On-Device Large Language Models for Clinical Decision Support",
      "link": "https://arxiv.org/abs/2601.03266",
      "summary": "arXiv:2601.03266v1 Announce Type: cross \nAbstract: Large language models (LLMs) have rapidly advanced in clinical decision-making, yet the deployment of proprietary systems is hindered by privacy concerns and reliance on cloud-based infrastructure. Open-source alternatives allow local inference but often require large model sizes that limit their use in resource-constrained clinical settings. Here, we benchmark two on-device LLMs, gpt-oss-20b and gpt-oss-120b, across three representative clinica",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "OpenAI GPT-5 System Card",
      "link": "https://arxiv.org/abs/2601.03267",
      "summary": "arXiv:2601.03267v1 Announce Type: cross \nAbstract: This is the system card published alongside the OpenAI GPT-5 launch, August 2025.\n  GPT-5 is a unified system with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and a real-time router that quickly decides which model to use based on conversation type, complexity, tool needs, and explicit intent (for example, if you say 'think hard about this' in the prompt). The router is continuously trained o",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Instruction Gap: LLMs get lost in Following Instruction",
      "link": "https://arxiv.org/abs/2601.03269",
      "summary": "arXiv:2601.03269v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) have shown remarkable capabilities in natural language understanding and generation, yet their deployment in enterprise environments reveals a critical limitation: inconsistent adherence to custom instructions. This study presents a comprehensive evaluation of 13 leading LLMs across instruction compliance, response accuracy, and performance metrics in realworld RAG (Retrieval-Augmented Generation) scenarios. Through ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Advances and Challenges in Semantic Textual Similarity: A Comprehensive Survey",
      "link": "https://arxiv.org/abs/2601.03270",
      "summary": "arXiv:2601.03270v1 Announce Type: cross \nAbstract: Semantic Textual Similarity (STS) research has expanded rapidly since 2021, driven by advances in transformer architectures, contrastive learning, and domain-specific techniques. This survey reviews progress across six key areas: transformer-based models, contrastive learning, domain-focused solutions, multi-modal methods, graph-based approaches, and knowledge-enhanced techniques. Recent transformer models such as FarSSiBERT and DeBERTa-v3 have ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Less is more: Not all samples are effective for evaluation",
      "link": "https://arxiv.org/abs/2601.03272",
      "summary": "arXiv:2601.03272v1 Announce Type: cross \nAbstract: The versatility of Large Language Models (LLMs) in vertical domains has spurred the development of numerous specialized evaluation benchmarks. However, these benchmarks often suffer from significant semantic redundancy and impose high computational costs during evaluation. Existing compression methods, such as tinyBenchmarks depend critically on correctness labels from multiple historical models evaluated on the full test set, making them inappl",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "GuardEval: A Multi-Perspective Benchmark for Evaluating Safety, Fairness, and Robustness in LLM Moderators",
      "link": "https://arxiv.org/abs/2601.03273",
      "summary": "arXiv:2601.03273v1 Announce Type: cross \nAbstract: As large language models (LLMs) become deeply embedded in daily life, the urgent need for safer moderation systems, distinguishing between naive from harmful requests while upholding appropriate censorship boundaries, has never been greater. While existing LLMs can detect harmful or unsafe content, they often struggle with nuanced cases such as implicit offensiveness, subtle gender and racial biases, and jailbreak prompts, due to the subjective ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LLM_annotate: A Python package for annotating and analyzing fiction characters",
      "link": "https://arxiv.org/abs/2601.03274",
      "summary": "arXiv:2601.03274v1 Announce Type: cross \nAbstract: LLM_annotate is a Python package for analyzing the personality of fiction characters with large language models. It standardizes workflows for annotating character behaviors in full texts (e.g., books and movie scripts), inferring character traits, and validating annotation/inference quality via a human-in-the-loop GUI. The package includes functions for text chunking, LLM-based annotation, character name disambiguation, quality scoring, and com",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Topic Segmentation Using Generative Language Models",
      "link": "https://arxiv.org/abs/2601.03276",
      "summary": "arXiv:2601.03276v1 Announce Type: cross \nAbstract: Topic segmentation using generative Large Language Models (LLMs) remains relatively unexplored. Previous methods use semantic similarity between sentences, but such models lack the long range dependencies and vast knowledge found in LLMs. In this work, we propose an overlapping and recursive prompting strategy using sentence enumeration. We also support the adoption of the boundary similarity evaluation metric. Results show that LLMs can be more",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MixRx: Predicting Drug Combination Interactions with LLMs",
      "link": "https://arxiv.org/abs/2601.03277",
      "summary": "arXiv:2601.03277v1 Announce Type: cross \nAbstract: MixRx uses Large Language Models (LLMs) to classify drug combination interactions as Additive, Synergistic, or Antagonistic, given a multi-drug patient history. We evaluate the performance of 4 models, GPT-2, Mistral Instruct 2.0, and the fine-tuned counterparts. Our results showed a potential for such an application, with the Mistral Instruct 2.0 Fine-Tuned model providing an average accuracy score on standard and perturbed datasets of 81.5%. T",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Quantum Model for Constrained Markowitz Modern Portfolio Using Slack Variables to Process Mixed-Binary Optimization under QAOA",
      "link": "https://arxiv.org/abs/2601.03278",
      "summary": "arXiv:2601.03278v1 Announce Type: cross \nAbstract: Effectively encoding inequality constraints is a primary obstacle in applying quantum algorithms to financial optimization. A quantum model for Markowitz portfolio optimization is presented that resolves this by embedding slack variables directly into the problem Hamiltonian. The method maps each slack variable to a dedicated ancilla qubit, transforming the problem into a Quadratic Unconstrained Binary Optimization (QUBO) formulation suitable fo",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "$\\alpha^3$-Bench: A Unified Benchmark of Safety, Robustness, and Efficiency for LLM-Based UAV Agents over 6G Networks",
      "link": "https://arxiv.org/abs/2601.03281",
      "summary": "arXiv:2601.03281v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) are increasingly used as high level controllers for autonomous Unmanned Aerial Vehicle (UAV) missions. However, existing evaluations rarely assess whether such agents remain safe, protocol compliant, and effective under realistic next generation networking constraints. This paper introduces $\\alpha^3$-Bench, a benchmark for evaluating LLM driven UAV autonomy as a multi turn conversational reasoning and control proble",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AI-Guided Discovery of Novel Ionic Liquid Solvents for Industrial CO2 Capture",
      "link": "https://arxiv.org/abs/2601.03284",
      "summary": "arXiv:2601.03284v1 Announce Type: cross \nAbstract: We present an AI-driven approach to discover compounds with optimal properties for CO2 capture from flue gas-refinery emissions' primary source. Focusing on ionic liquids (ILs) as alternatives to traditional amine-based solvents, we successfully identify new IL candidates with high working capacity, manageable viscosity, favorable regeneration energy, and viable synthetic routes. Our approach follows a five-stage pipeline. First, we generate IL ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Feedback Indices to Evaluate LLM Responses to Rebuttals for Multiple Choice Type Questions",
      "link": "https://arxiv.org/abs/2601.03285",
      "summary": "arXiv:2601.03285v1 Announce Type: cross \nAbstract: We present a systematic framework of indices designed to characterize Large Language Model (LLM) responses when challenged with rebuttals during a chat. Assessing how LLMs respond to user dissent is crucial for understanding their reliability and behavior patterns, yet the complexity of human-LLM interactions makes systematic evaluation challenging. Our approach employs a fictitious-response rebuttal method that quantifies LLM behavior when pres",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "HyperCLOVA X 32B Think",
      "link": "https://arxiv.org/abs/2601.03286",
      "summary": "arXiv:2601.03286v1 Announce Type: cross \nAbstract: In this report, we present HyperCLOVA X 32B Think, a vision-language model designed with particular emphasis on reasoning within the Korean linguistic and cultural context, as well as agentic ability. HyperCLOVA X 32B Think is pre-trained with a strong focus on reasoning capabilities and subsequently post-trained to support multimodal understanding, enhanced reasoning, agentic behaviors, and alignment with human preferences. Experimental evaluat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Automated Post-Incident Policy Gap Analysis via Threat-Informed Evidence Mapping using Large Language Models",
      "link": "https://arxiv.org/abs/2601.03287",
      "summary": "arXiv:2601.03287v1 Announce Type: cross \nAbstract: Cybersecurity post-incident reviews are essential for identifying control failures and improving organisational resilience, yet they remain labour-intensive, time-consuming, and heavily reliant on expert judgment. This paper investigates whether Large Language Models (LLMs) can augment post-incident review workflows by autonomously analysing system evidence and identifying security policy gaps. We present a threat-informed, agentic framework tha",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Lightweight Transformer Architectures for Edge Devices in Real-Time Applications",
      "link": "https://arxiv.org/abs/2601.03290",
      "summary": "arXiv:2601.03290v1 Announce Type: cross \nAbstract: The deployment of transformer-based models on resource-constrained edge devices represents a critical challenge in enabling real-time artificial intelligence applications. This comprehensive survey examines lightweight transformer architectures specifically designed for edge deployment, analyzing recent advances in model compression, quantization, pruning, and knowledge distillation techniques. We systematically review prominent lightweight vari",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AgentMark: Utility-Preserving Behavioral Watermarking for Agents",
      "link": "https://arxiv.org/abs/2601.03294",
      "summary": "arXiv:2601.03294v1 Announce Type: cross \nAbstract: LLM-based agents are increasingly deployed to autonomously solve complex tasks, raising urgent needs for IP protection and regulatory provenance. While content watermarking effectively attributes LLM-generated outputs, it fails to directly identify the high-level planning behaviors (e.g., tool and subgoal choices) that govern multi-step execution. Critically, watermarking at the planning-behavior layer faces unique challenges: minor distribution",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "130k Lines of Formal Topology in Two Weeks: Simple and Cheap Autoformalization for Everyone?",
      "link": "https://arxiv.org/abs/2601.03298",
      "summary": "arXiv:2601.03298v1 Announce Type: cross \nAbstract: This is a brief description of a project that has already autoformalized a large portion of the general topology from the Munkres textbook (which has in total 241 pages in 7 chapters and 39 sections). The project has been running since November 21, 2025 and has as of January 4, 2026, produced 160k lines of formalized topology. Most of it (about 130k lines) have been done in two weeks,from December 22 to January 4, for an LLM subscription cost of",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PC2P: Multi-Agent Path Finding via Personalized-Enhanced Communication and Crowd Perception",
      "link": "https://arxiv.org/abs/2601.03301",
      "summary": "arXiv:2601.03301v1 Announce Type: cross \nAbstract: Distributed Multi-Agent Path Finding (MAPF) integrated with Multi-Agent Reinforcement Learning (MARL) has emerged as a prominent research focus, enabling real-time cooperative decision-making in partially observable environments through inter-agent communication. However, due to insufficient collaborative and perceptual capabilities, existing methods are inadequate for scaling across diverse environmental conditions. To address these challenges,",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CageDroneRF: A Large-Scale RF Benchmark and Toolkit for Drone Perception",
      "link": "https://arxiv.org/abs/2601.03302",
      "summary": "arXiv:2601.03302v1 Announce Type: cross \nAbstract: We present CageDroneRF (CDRF), a large-scale benchmark for Radio-Frequency (RF) drone detection and identification built from real-world captures and systematically generated synthetic variants. CDRF addresses the scarcity and limited diversity of existing RF datasets by coupling extensive raw recordings with a principled augmentation pipeline that (i) precisely controls Signal-to-Noise Ratio (SNR), (ii) injects interfering emitters, and (iii) a",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AI-Driven Cybersecurity Threats: A Survey of Emerging Risks and Defensive Strategies",
      "link": "https://arxiv.org/abs/2601.03304",
      "summary": "arXiv:2601.03304v1 Announce Type: cross \nAbstract: Artificial Intelligence's dual-use nature is revolutionizing the cybersecurity landscape, introducing new threats across four main categories: deepfakes and synthetic media, adversarial AI attacks, automated malware, and AI-powered social engineering. This paper aims to analyze emerging risks, attack mechanisms, and defense shortcomings related to AI in cybersecurity. We introduce a comparative taxonomy connecting AI capabilities with threat mod",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy",
      "link": "https://arxiv.org/abs/2601.03305",
      "summary": "arXiv:2601.03305v1 Announce Type: cross \nAbstract: The success of diffusion models has raised concerns about the generation of unsafe or harmful content, prompting concept erasure approaches that fine-tune modules to suppress specific concepts while preserving general generative capabilities. However, as the number of erased concepts grows, these methods often become inefficient and ineffective, since each concept requires a separate set of fine-tuned parameters and may degrade the overall gener",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "VLM4VLA: Revisiting Vision-Language-Models in Vision-Language-Action Models",
      "link": "https://arxiv.org/abs/2601.03309",
      "summary": "arXiv:2601.03309v1 Announce Type: cross \nAbstract: Vision-Language-Action (VLA) models, which integrate pretrained large Vision-Language Models (VLM) into their policy backbone, are gaining significant attention for their promising generalization capabilities. This paper revisits a fundamental yet seldom systematically studied question: how VLM choice and competence translate to downstream VLA policies performance? We introduce VLM4VLA, a minimal adaptation pipeline that converts general-purpose",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts",
      "link": "https://arxiv.org/abs/2601.03315",
      "summary": "arXiv:2601.03315v1 Announce Type: cross \nAbstract: We report a case study of four end-to-end attempts to autonomously generate ML research papers using a pipeline of six LLM agents mapped to stages of the scientific workflow. Of these four, three attempts failed during implementation or evaluation. One completed the pipeline and was accepted to Agents4Science 2025, an experimental inaugural venue that required AI systems as first authors, passing both human and multi-AI review. From these attemp",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Deep Learning-Based Image Recognition for Soft-Shell Shrimp Classification",
      "link": "https://arxiv.org/abs/2601.03317",
      "summary": "arXiv:2601.03317v1 Announce Type: cross \nAbstract: With the integration of information technology into aquaculture, production has become more stable and continues to grow annually. As consumer demand for high-quality aquatic products rises, freshness and appearance integrity are key concerns. In shrimp-based processed foods, freshness declines rapidly post-harvest, and soft-shell shrimp often suffer from head-body separation after cooking or freezing, affecting product appearance and consumer p",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature",
      "link": "https://arxiv.org/abs/2601.03319",
      "summary": "arXiv:2601.03319v1 Announce Type: cross \nAbstract: A photorealistic and controllable 3D caricaturization framework for faces is introduced. We start with an intrinsic Gaussian curvature-based surface exaggeration technique, which, when coupled with texture, tends to produce over-smoothed renders. To address this, we resort to 3D Gaussian Splatting (3DGS), which has recently been shown to produce realistic free-viewpoint avatars. Given a multiview sequence, we extract a FLAME mesh, solve a curvat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Ratio-Variance Regularized Policy Optimization for Efficient LLM Fine-tuning",
      "link": "https://arxiv.org/abs/2601.03320",
      "summary": "arXiv:2601.03320v1 Announce Type: cross \nAbstract: On-policy reinforcement learning (RL), particularly Proximal Policy Optimization (PPO) and Group Relative Policy Optimization (GRPO), has become the dominant paradigm for fine-tuning large language models (LLMs). While policy ratio clipping stabilizes training, this heuristic hard constraint incurs a fundamental cost: it indiscriminately truncates gradients from high-return yet high-divergence actions, suppressing rare but highly informative \"eu",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Aligning Findings with Diagnosis: A Self-Consistent Reinforcement Learning Framework for Trustworthy Radiology Reporting",
      "link": "https://arxiv.org/abs/2601.03321",
      "summary": "arXiv:2601.03321v1 Announce Type: cross \nAbstract: Multimodal Large Language Models (MLLMs) have shown strong potential for radiology report generation, yet their clinical translation is hindered by architectural heterogeneity and the prevalence of factual hallucinations. Standard supervised fine-tuning often fails to strictly align linguistic outputs with visual evidence, while existing reinforcement learning approaches struggle with either prohibitive computational costs or limited exploration",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "HEEGNet: Hyperbolic Embeddings for EEG",
      "link": "https://arxiv.org/abs/2601.03322",
      "summary": "arXiv:2601.03322v1 Announce Type: cross \nAbstract: Electroencephalography (EEG)-based brain-computer interfaces facilitate direct communication with a computer, enabling promising applications in human-computer interactions. However, their utility is currently limited because EEG decoding often suffers from poor generalization due to distribution shifts across domains (e.g., subjects). Learning robust representations that capture underlying task-relevant information would mitigate these shifts a",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Bare-Metal Tensor Virtualization: Overcoming the Memory Wall in Edge-AI Inference on ARM64",
      "link": "https://arxiv.org/abs/2601.03324",
      "summary": "arXiv:2601.03324v1 Announce Type: cross \nAbstract: The deployment of Large Language Models (LLMs) on edge devices is fundamentally constrained by the \"Memory Wall\" the bottleneck where data movement latency outstrips arithmetic throughput. Standard inference runtimes often incur significant overhead through high-level abstractions, dynamic dispatch, and unaligned memory access patterns. In this work, we present a novel \"Virtual Tensor Core\" architecture implemented in software, optimized specifi",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Extreme-value forest fire prediction A study of the Loss Function in an Ordinality Scheme",
      "link": "https://arxiv.org/abs/2601.03327",
      "summary": "arXiv:2601.03327v2 Announce Type: cross \nAbstract: Wildfires are highly imbalanced natural hazards in both space and severity, making the prediction of extreme events particularly challenging. In this work, we introduce the first ordinal classification framework for forecasting wildfire severity levels directly aligned with operational decision-making in France. Our study investigates the influence of loss-function design on the ability of neural models to predict rare yet critical high-severity",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Attention mechanisms in neural networks",
      "link": "https://arxiv.org/abs/2601.03329",
      "summary": "arXiv:2601.03329v1 Announce Type: cross \nAbstract: Attention mechanisms represent a fundamental paradigm shift in neural network architectures, enabling models to selectively focus on relevant portions of input sequences through learned weighting functions. This monograph provides a comprehensive and rigorous mathematical treatment of attention mechanisms, encompassing their theoretical foundations, computational properties, and practical implementations in contemporary deep learning systems. Ap",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MMErroR: A Benchmark for Erroneous Reasoning in Vision-Language Models",
      "link": "https://arxiv.org/abs/2601.03331",
      "summary": "arXiv:2601.03331v1 Announce Type: cross \nAbstract: Recent advances in Vision-Language Models (VLMs) have improved performance in multi-modal learning, raising the question of whether these models truly understand the content they process. Crucially, can VLMs detect when a reasoning process is wrong and identify its error type? To answer this, we present MMErroR, a multi-modal benchmark of 2,013 samples, each embedding a single coherent reasoning error. These samples span 24 subdomains across six",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Metaphors are a Source of Cross-Domain Misalignment of Large Reasoning Models",
      "link": "https://arxiv.org/abs/2601.03388",
      "summary": "arXiv:2601.03388v1 Announce Type: cross \nAbstract: Earlier research has shown that metaphors influence human's decision making, which raises the question of whether metaphors also influence large language models (LLMs)' reasoning pathways, considering their training data contain a large number of metaphors. In this work, we investigate the problem in the scope of the emergent misalignment problem where LLMs can generalize patterns learned from misaligned content in one domain to another domain. ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Eye-Q: A Multilingual Benchmark for Visual Word Puzzle Solving and Image-to-Phrase Reasoning",
      "link": "https://arxiv.org/abs/2601.03400",
      "summary": "arXiv:2601.03400v1 Announce Type: cross \nAbstract: Vision-Language Models (VLMs) have achieved strong performance on standard vision-language benchmarks, yet often rely on surface-level recognition rather than deeper reasoning. We propose visual word puzzles as a challenging alternative, as they require discovering implicit visual cues, generating and revising hypotheses, and mapping perceptual evidence to non-literal concepts in ways that are difficult to solve via literal grounding, OCR-heavy ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Tigrinya Number Verbalization: Rules, Algorithm, and Implementation",
      "link": "https://arxiv.org/abs/2601.03403",
      "summary": "arXiv:2601.03403v1 Announce Type: cross \nAbstract: We present a systematic formalization of Tigrinya cardinal and ordinal number verbalization, addressing a gap in computational resources for the language. This work documents the canonical rules governing the expression of numerical values in spoken Tigrinya, including the conjunction system, scale words, and special cases for dates, times, and currency. We provide a formal algorithm for number-to-word conversion and release an open-source imple",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Jailbreaking LLMs Without Gradients or Priors: Effective and Transferable Attacks",
      "link": "https://arxiv.org/abs/2601.03420",
      "summary": "arXiv:2601.03420v1 Announce Type: cross \nAbstract: As Large Language Models (LLMs) are increasingly deployed in safety-critical domains, rigorously evaluating their robustness against adversarial jailbreaks is essential. However, current safety evaluations often overestimate robustness because existing automated attacks are limited by restrictive assumptions. They typically rely on handcrafted priors or require white-box access for gradient propagation. We challenge these constraints by demonstr",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Training-Free Adaptation of New-Generation LLMs using Legacy Clinical Models",
      "link": "https://arxiv.org/abs/2601.03423",
      "summary": "arXiv:2601.03423v1 Announce Type: cross \nAbstract: Adapting language models to the clinical domain through continued pretraining and fine-tuning requires costly retraining for each new model generation. We propose Cross-Architecture Proxy Tuning (CAPT), a model-ensembling approach that enables training-free adaptation of state-of-the-art general-domain models using existing clinical models. CAPT supports models with disjoint vocabularies, leveraging contrastive decoding to selectively inject cli",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Spectral Archaeology: The Causal Topology of Model Evolution",
      "link": "https://arxiv.org/abs/2601.03424",
      "summary": "arXiv:2601.03424v1 Announce Type: cross \nAbstract: Behavioral benchmarks tell us \\textit{what} a model does, but not \\textit{how}. We introduce a training-free mechanistic probe using attention-graph spectra. Treating each layer as a token graph, we compute algebraic connectivity ($\\lambda_2$), smoothness, and spectral entropy. Across 12 models and 10 languages, these measures yield stable ``spectral fingerprints'' that expose discontinuities missed by standard evaluation.\n  We report four resul",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Illusion of Specialization: Unveiling the Domain-Invariant \"Standing Committee\" in Mixture-of-Experts Models",
      "link": "https://arxiv.org/abs/2601.03425",
      "summary": "arXiv:2601.03425v1 Announce Type: cross \nAbstract: Mixture of Experts models are widely assumed to achieve domain specialization through sparse routing. In this work, we question this assumption by introducing COMMITTEEAUDIT, a post hoc framework that analyzes routing behavior at the level of expert groups rather than individual experts. Across three representative models and the MMLU benchmark, we uncover a domain-invariant Standing Committee. This is a compact coalition of routed experts that ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MARVEL: A Multi Agent-based Research Validator and Enabler using Large Language Models",
      "link": "https://arxiv.org/abs/2601.03436",
      "summary": "arXiv:2601.03436v1 Announce Type: cross \nAbstract: We present MARVEL (https://ligogpt.mit.edu/marvel), a locally deployable, open-source framework for domain-aware question answering and assisted scientific research. It is designed to address the increasing demands of a digital assistant for scientific groups that can read highly technical data, cite precisely, and operate within authenticated networks. MARVEL combines a fast path for straightforward queries with a more deliberate DeepSearch mod",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Discriminating real and synthetic super-resolved audio samples using embedding-based classifiers",
      "link": "https://arxiv.org/abs/2601.03443",
      "summary": "arXiv:2601.03443v1 Announce Type: cross \nAbstract: Generative adversarial networks (GANs) and diffusion models have recently achieved state-of-the-art performance in audio super-resolution (ADSR), producing perceptually convincing wideband audio from narrowband inputs. However, existing evaluations primarily rely on signal-level or perceptual metrics, leaving open the question of how closely the distributions of synthetic super-resolved and real wideband audio match. Here we address this problem",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Grading Scale Impact on LLM-as-a-Judge: Human-LLM Alignment Is Highest on 0-5 Grading Scale",
      "link": "https://arxiv.org/abs/2601.03444",
      "summary": "arXiv:2601.03444v1 Announce Type: cross \nAbstract: Large language models (LLMs) are increasingly used as automated evaluators, yet prior works demonstrate that these LLM judges often lack consistency in scoring when the prompt is altered. However, the effect of the grading scale itself remains underexplored. We study the LLM-as-a-judge problem by comparing two kinds of raters: humans and LLMs. We collect ratings from both groups on three scales and across six benchmarks that include objective, o",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Soft Contextualized Encoder For User Defined Text Classification",
      "link": "https://arxiv.org/abs/2601.03450",
      "summary": "arXiv:2601.03450v1 Announce Type: cross \nAbstract: User-Defined Text Classification (UDTC) considers the challenge of classifying input text to user-specified, previously unseen classes, a setting that arises frequently in real-world applications such as enterprise analytics, content moderation, and domain-specific information retrieval. We propose a soft-contextualized encoder architecture for UDTC which contextualizes each candidate label with the label set and a static soft prompt representat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Microeconomic Foundations of Multi-Agent Learning",
      "link": "https://arxiv.org/abs/2601.03451",
      "summary": "arXiv:2601.03451v1 Announce Type: cross \nAbstract: Modern AI systems increasingly operate inside markets and institutions where data, behavior, and incentives are endogenous. This paper develops an economic foundation for multi-agent learning by studying a principal-agent interaction in a Markov decision process with strategic externalities, where both the principal and the agent learn over time. We propose a two-phase incentive mechanism that first estimates implementable transfers and then use",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Automated Feedback Generation for Undergraduate Mathematics: Development and Evaluation of an AI Teaching Assistant",
      "link": "https://arxiv.org/abs/2601.03458",
      "summary": "arXiv:2601.03458v1 Announce Type: cross \nAbstract: Intelligent tutoring systems have long enabled automated immediate feedback on student work when it is presented in a tightly structured format and when problems are very constrained, but reliably assessing free-form mathematical reasoning remains challenging.\n  We present a system that processes free-form natural language input, handles a wide range of edge cases, and comments competently not only on the technical correctness of submitted proof",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An Expectation-Maximization Algorithm for Domain Adaptation in Gaussian Causal Models",
      "link": "https://arxiv.org/abs/2601.03459",
      "summary": "arXiv:2601.03459v1 Announce Type: cross \nAbstract: We study the problem of imputing a designated target variable that is systematically missing in a shifted deployment domain, when a Gaussian causal DAG is available from a fully observed source domain. We propose a unified EM-based framework that combines source and target data through the DAG structure to transfer information from observed variables to the missing target. On the methodological side, we formulate a population EM operator in the ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FROST-Drive: Scalable and Efficient End-to-End Driving with a Frozen Vision Encoder",
      "link": "https://arxiv.org/abs/2601.03460",
      "summary": "arXiv:2601.03460v1 Announce Type: cross \nAbstract: End-to-end (E2E) models in autonomous driving aim to directly map sensor inputs to control commands, but their ability to generalize to novel and complex scenarios remains a key challenge. The common practice of fully fine-tuning the vision encoder on driving datasets potentially limits its generalization by causing the model to specialize too heavily in the training data. This work challenges the necessity of this training paradigm. We propose ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Content vs. Form: What Drives the Writing Score Gap Across Socioeconomic Backgrounds? A Generated Panel Approach",
      "link": "https://arxiv.org/abs/2601.03469",
      "summary": "arXiv:2601.03469v1 Announce Type: cross \nAbstract: Students from different socioeconomic backgrounds exhibit persistent gaps in test scores, gaps that can translate into unequal educational and labor-market outcomes later in life. In many assessments, performance reflects not only what students know, but also how effectively they can communicate that knowledge. This distinction is especially salient in writing assessments, where scores jointly reward the substance of students' ideas and the way ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "EpiQAL: Benchmarking Large Language Models in Epidemiological Question Answering for Enhanced Alignment and Reasoning",
      "link": "https://arxiv.org/abs/2601.03471",
      "summary": "arXiv:2601.03471v1 Announce Type: cross \nAbstract: Reliable epidemiological reasoning requires synthesizing study evidence to infer disease burden, transmission dynamics, and intervention effects at the population level. Existing medical question answering benchmarks primarily emphasize clinical knowledge or patient-level reasoning, yet few systematically evaluate evidence-grounded epidemiological inference. We present EpiQAL, the first diagnostic benchmark for epidemiological question answering",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SegNSP: Revisiting Next Sentence Prediction for Linear Text Segmentation",
      "link": "https://arxiv.org/abs/2601.03474",
      "summary": "arXiv:2601.03474v1 Announce Type: cross \nAbstract: Linear text segmentation is a long-standing problem in natural language processing (NLP), focused on dividing continuous text into coherent and semantically meaningful units. Despite its importance, the task remains challenging due to the complexity of defining topic boundaries, the variability in discourse structure, and the need to balance local coherence with global context. These difficulties hinder downstream applications such as summarizat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Online Decision-Making Under Uncertainty for Vehicle-to-Building Systems",
      "link": "https://arxiv.org/abs/2601.03476",
      "summary": "arXiv:2601.03476v1 Announce Type: cross \nAbstract: Vehicle-to-building (V2B) systems integrate physical infrastructures, such as smart buildings and electric vehicles (EVs) connected to chargers at the building, with digital control mechanisms to manage energy use. By utilizing EVs as flexible energy reservoirs, buildings can dynamically charge and discharge them to optimize energy use and cut costs under time-variable pricing and demand charge policies. This setup leads to the V2B optimization ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Efficient Sequential Recommendation for Long Term User Interest Via Personalization",
      "link": "https://arxiv.org/abs/2601.03479",
      "summary": "arXiv:2601.03479v1 Announce Type: cross \nAbstract: Recent years have witnessed success of sequential modeling, generative recommender, and large language model for recommendation. Though the scaling law has been validated for sequential models, it showed inefficiency in computational capacity when considering real-world applications like recommendation, due to the non-linear(quadratic) increasing nature of the transformer model. To improve the efficiency of the sequential model, we introduced a ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CroBIM-U: Uncertainty-Driven Referring Remote Sensing Image Segmentation",
      "link": "https://arxiv.org/abs/2601.03490",
      "summary": "arXiv:2601.03490v1 Announce Type: cross \nAbstract: Referring remote sensing image segmentation aims to localize specific targets described by natural language within complex overhead imagery. However, due to extreme scale variations, dense similar distractors, and intricate boundary structures, the reliability of cross-modal alignment exhibits significant \\textbf{spatial non-uniformity}. Existing methods typically employ uniform fusion and refinement strategies across the entire image, which oft",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Submodular Evaluation Subset Selection in Automatic Prompt Optimization",
      "link": "https://arxiv.org/abs/2601.03493",
      "summary": "arXiv:2601.03493v1 Announce Type: cross \nAbstract: Automatic prompt optimization reduces manual prompt engineering, but relies on task performance measured on a small, often randomly sampled evaluation subset as its main source of feedback signal. Despite this, how to select that evaluation subset is usually treated as an implementation detail. We study evaluation subset selection for prompt optimization from a principled perspective and propose SESS, a submodular evaluation subset selection met",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Cyberattack Detection in Virtualized Microgrids Using LightGBM and Knowledge-Distilled Classifiers",
      "link": "https://arxiv.org/abs/2601.03495",
      "summary": "arXiv:2601.03495v1 Announce Type: cross \nAbstract: Modern microgrids depend on distributed sensing and communication interfaces, making them increasingly vulnerable to cyber physical disturbances that threaten operational continuity and equipment safety. In this work, a complete virtual microgrid was designed and implemented in MATLAB/Simulink, integrating heterogeneous renewable sources and secondary controller layers. A structured cyberattack framework was developed using MGLib to inject adver",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models",
      "link": "https://arxiv.org/abs/2601.03500",
      "summary": "arXiv:2601.03500v1 Announce Type: cross \nAbstract: Large Vision-Language Models (LVLMs) demonstrate significant progress in multimodal understanding and reasoning, yet object hallucination remains a critical challenge. While existing research focuses on mitigating language priors or high-level statistical biases, they often overlook the internal complexities of the visual encoding process. We identify that visual statistical bias, arising from the inherent Bag-of-Patches behavior of Vision Encod",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Beyond Perplexity: A Lightweight Benchmark for Knowledge Retention in Supervised Fine-Tuning",
      "link": "https://arxiv.org/abs/2601.03505",
      "summary": "arXiv:2601.03505v1 Announce Type: cross \nAbstract: Supervised Fine-Tuning (SFT) is a standard approach for injecting domain knowledge into Large Language Models (LLMs). However, relying on validation perplexity to monitor training is often insufficient, as it confounds stylistic mimicry with genuine factual internalization. To address this, we introduce the Knowledge Retention (KR) Test , a lightweight, corpus-grounded evaluation framework designed to distinguish factual learning from linguistic",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Reasoning Pattern Alignment Merging for Adaptive Reasoning",
      "link": "https://arxiv.org/abs/2601.03506",
      "summary": "arXiv:2601.03506v1 Announce Type: cross \nAbstract: Recent large reasoning models (LRMs) have made substantial progress in complex reasoning tasks, yet they often generate lengthy reasoning paths for every query, incurring unnecessary computation and latency. Existing speed-up approaches typically rely on retraining the model or designing sophisticated prompting, which are either prohibitively expensive or highly sensitive to the input and prompt formulation. In this work, we study model merging ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "IntroLM: Introspective Language Models via Prefilling-Time Self-Evaluation",
      "link": "https://arxiv.org/abs/2601.03511",
      "summary": "arXiv:2601.03511v1 Announce Type: cross \nAbstract: A major challenge for the operation of large language models (LLMs) is how to predict whether a specific LLM will produce sufficiently high-quality output for a given query. Existing approaches rely on external classifiers, most commonly BERT based models, which suffer from limited context windows, constrained representational capacity, and additional computational overhead. We propose IntroLM, a method that enables causal language models to pre",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Bootstrapping Code Translation with Weighted Multilanguage Exploration",
      "link": "https://arxiv.org/abs/2601.03512",
      "summary": "arXiv:2601.03512v1 Announce Type: cross \nAbstract: Code translation across multiple programming languages is essential yet challenging due to two vital obstacles: scarcity of parallel data paired with executable test oracles, and optimization imbalance when handling diverse language pairs. We propose BootTrans, a bootstrapping method that resolves both obstacles. Its key idea is to leverage the functional invariance and cross-lingual portability of test suites, adapting abundant pivot-language u",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Deploy-Master: Automating the Deployment of 50,000+ Agent-Ready Scientific Tools in One Day",
      "link": "https://arxiv.org/abs/2601.03513",
      "summary": "arXiv:2601.03513v1 Announce Type: cross \nAbstract: Open-source scientific software is abundant, yet most tools remain difficult to compile, configure, and reuse, sustaining a small-workshop mode of scientific computing. This deployment bottleneck limits reproducibility, large-scale evaluation, and the practical integration of scientific tools into modern AI-for-Science (AI4S) and agentic workflows.\n  We present Deploy-Master, a one-stop agentic workflow for large-scale tool discovery, build spec",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Mem-Gallery: Benchmarking Multimodal Long-Term Conversational Memory for MLLM Agents",
      "link": "https://arxiv.org/abs/2601.03515",
      "summary": "arXiv:2601.03515v1 Announce Type: cross \nAbstract: Long-term memory is a critical capability for multimodal large language model (MLLM) agents, particularly in conversational settings where information accumulates and evolves over time. However, existing benchmarks either evaluate multi-session memory in text-only conversations or assess multimodal understanding within localized contexts, failing to evaluate how multimodal memory is preserved, organized, and evolved across long-term conversation",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Reinforcement Learning-Based Model for Mapping and Goal-Directed Navigation Using Multiscale Place Fields",
      "link": "https://arxiv.org/abs/2601.03520",
      "summary": "arXiv:2601.03520v1 Announce Type: cross \nAbstract: Autonomous navigation in complex and partially observable environments remains a central challenge in robotics. Several bio-inspired models of mapping and navigation based on place cells in the mammalian hippocampus have been proposed. This paper introduces a new robust model that employs parallel layers of place fields at multiple spatial scales, a replay-based reward mechanism, and dynamic scale fusion. Simulations show that the model improves",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "VeRPO: Verifiable Dense Reward Policy Optimization for Code Generation",
      "link": "https://arxiv.org/abs/2601.03525",
      "summary": "arXiv:2601.03525v1 Announce Type: cross \nAbstract: Effective reward design is a central challenge in Reinforcement Learning (RL) for code generation. Mainstream pass/fail outcome rewards enforce functional correctness via executing unit tests, but the resulting sparsity limits potential performance gains. While recent work has explored external Reward Models (RM) to generate richer, continuous rewards, the learned RMs suffer from reward misalignment and prohibitive computational cost. In this pa",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Layer-Order Inversion: Rethinking Latent Multi-Hop Reasoning in Large Language Models",
      "link": "https://arxiv.org/abs/2601.03542",
      "summary": "arXiv:2601.03542v1 Announce Type: cross \nAbstract: Large language models (LLMs) perform well on multi-hop reasoning, yet how they internally compose multiple facts remains unclear. Recent work proposes \\emph{hop-aligned circuit hypothesis}, suggesting that bridge entities are computed sequentially across layers before later-hop answers. Through systematic analyses on real-world multi-hop queries, we show that this hop-aligned assumption does not generalize: later-hop answer entities can become d",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Value-Action Alignment in Large Language Models under Privacy-Prosocial Conflict",
      "link": "https://arxiv.org/abs/2601.03546",
      "summary": "arXiv:2601.03546v1 Announce Type: cross \nAbstract: Large language models (LLMs) are increasingly used to simulate decision-making tasks involving personal data sharing, where privacy concerns and prosocial motivations can push choices in opposite directions. Existing evaluations often measure privacy-related attitudes or sharing intentions in isolation, which makes it difficult to determine whether a model's expressed values jointly predict its downstream data-sharing actions as in real human be",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Evaluating LLMs for Police Decision-Making: A Framework Based on Police Action Scenarios",
      "link": "https://arxiv.org/abs/2601.03553",
      "summary": "arXiv:2601.03553v1 Announce Type: cross \nAbstract: The use of Large Language Models (LLMs) in police operations is growing, yet an evaluation framework tailored to police operations remains absent. While LLM's responses may not always be legally incorrect, their unverified use still can lead to severe issues such as unlawful arrests and improper evidence collection. To address this, we propose PAS (Police Action Scenarios), a systematic framework covering the entire evaluation process. Applying ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Proposed Paradigm for Imputing Missing Multi-Sensor Data in the Healthcare Domain",
      "link": "https://arxiv.org/abs/2601.03565",
      "summary": "arXiv:2601.03565v1 Announce Type: cross \nAbstract: Chronic diseases such as diabetes pose significant management challenges, particularly due to the risk of complications like hypoglycemia, which require timely detection and intervention. Continuous health monitoring through wearable sensors offers a promising solution for early prediction of glycemic events. However, effective use of multisensor data is hindered by issues such as signal noise and frequent missing values. This study examines the",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Deontic Knowledge Graphs for Privacy Compliance in Multimodal Disaster Data Sharing",
      "link": "https://arxiv.org/abs/2601.03587",
      "summary": "arXiv:2601.03587v1 Announce Type: cross \nAbstract: Disaster response requires sharing heterogeneous artifacts, from tabular assistance records to UAS imagery, under overlapping privacy mandates. Operational systems often reduce compliance to binary access control, which is brittle in time-critical workflows. We present a novel deontic knowledge graph-based framework that integrates a Disaster Management Knowledge Graph (DKG) with a Policy Knowledge Graph (PKG) derived from IoT-Reg and FEMA/DHS p",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Can LLMs See Without Pixels? Benchmarking Spatial Intelligence from Textual Descriptions",
      "link": "https://arxiv.org/abs/2601.03590",
      "summary": "arXiv:2601.03590v1 Announce Type: cross \nAbstract: Recent advancements in Spatial Intelligence (SI) have predominantly relied on Vision-Language Models (VLMs), yet a critical question remains: does spatial understanding originate from visual encoders or the fundamental reasoning backbone? Inspired by this question, we introduce SiT-Bench, a novel benchmark designed to evaluate the SI performance of Large Language Models (LLMs) without pixel-level input, comprises over 3,800 expert-annotated item",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "From Chains to Graphs: Self-Structured Reasoning for General-Domain LLMs",
      "link": "https://arxiv.org/abs/2601.03597",
      "summary": "arXiv:2601.03597v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) show strong reasoning ability in open-domain question answering, yet their reasoning processes are typically linear and often logically inconsistent. In contrast, real-world reasoning requires integrating multiple premises and solving subproblems in parallel. Existing methods, such as Chain-of-Thought (CoT), express reasoning in a linear textual form, which may appear coherent but frequently leads to inconsistent con",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ALERT: Zero-shot LLM Jailbreak Detection via Internal Discrepancy Amplification",
      "link": "https://arxiv.org/abs/2601.03600",
      "summary": "arXiv:2601.03600v1 Announce Type: cross \nAbstract: Despite rich safety alignment strategies, large language models (LLMs) remain highly susceptible to jailbreak attacks, which compromise safety guardrails and pose serious security risks. Existing detection methods mainly detect jailbreak status relying on jailbreak templates present in the training data. However, few studies address the more realistic and challenging zero-shot jailbreak detection setting, where no jailbreak templates are availab",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Policy-Guided Search on Tree-of-Thoughts for Efficient Problem Solving with Bounded Language Model Queries",
      "link": "https://arxiv.org/abs/2601.03606",
      "summary": "arXiv:2601.03606v1 Announce Type: cross \nAbstract: Recent studies explored integrating state-space search algorithms with Language Models (LM) to perform look-ahead on the token generation process, the ''Tree-of-Thoughts'' (ToT), generated by LMs, thereby improving performance on problem-solving tasks. However, the affiliated search algorithms often overlook the significant computational costs associated with LM inference, particularly in scenarios with constrained computational budgets. Consequ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Investigation into respiratory sound classification for an imbalanced data set using hybrid LSTM-KAN architectures",
      "link": "https://arxiv.org/abs/2601.03610",
      "summary": "arXiv:2601.03610v1 Announce Type: cross \nAbstract: Respiratory sounds captured via auscultation contain critical clues for diagnosing pulmonary conditions. Automated classification of these sounds faces challenges due to subtle acoustic differences and severe class imbalance in clinical datasets. This study investigates respiratory sound classification with a focus on mitigating pronounced class imbalance. We propose a hybrid deep learning model that combines a Long Short-Term Memory (LSTM) netw",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Evaluating the Pre-Consultation Ability of LLMs using Diagnostic Guidelines",
      "link": "https://arxiv.org/abs/2601.03627",
      "summary": "arXiv:2601.03627v2 Announce Type: cross \nAbstract: We introduce EPAG, a benchmark dataset and framework designed for Evaluating the Pre-consultation Ability of LLMs using diagnostic Guidelines. LLMs are evaluated directly through HPI-diagnostic guideline comparison and indirectly through disease diagnosis. In our experiments, we observe that small open-source models fine-tuned with a well-curated, task-specific dataset can outperform frontier LLMs in pre-consultation. Additionally, we find that ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ReStyle-TTS: Relative and Continuous Style Control for Zero-Shot Speech Synthesis",
      "link": "https://arxiv.org/abs/2601.03632",
      "summary": "arXiv:2601.03632v1 Announce Type: cross \nAbstract: Zero-shot text-to-speech models can clone a speaker's timbre from a short reference audio, but they also strongly inherit the speaking style present in the reference. As a result, synthesizing speech with a desired style often requires carefully selecting reference audio, which is impractical when only limited or mismatched references are available. While recent controllable TTS methods attempt to address this issue, they typically rely on absol",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MFC-RFNet: A Multi-scale Guided Rectified Flow Network for Radar Sequence Prediction",
      "link": "https://arxiv.org/abs/2601.03633",
      "summary": "arXiv:2601.03633v1 Announce Type: cross \nAbstract: Accurate and high-resolution precipitation nowcasting from radar echo sequences is crucial for disaster mitigation and economic planning, yet it remains a significant challenge. Key difficulties include modeling complex multi-scale evolution, correcting inter-frame feature misalignment caused by displacement, and efficiently capturing long-range spatiotemporal context without sacrificing spatial fidelity. To address these issues, we present the ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ReLA: Representation Learning and Aggregation for Job Scheduling with Reinforcement Learning",
      "link": "https://arxiv.org/abs/2601.03646",
      "summary": "arXiv:2601.03646v2 Announce Type: cross \nAbstract: Job scheduling is widely used in real-world manufacturing systems to assign ordered job operations to machines under various constraints. Existing solutions remain limited by long running time or insufficient schedule quality, especially when problem scale increases. In this paper, we propose ReLA, a reinforcement-learning (RL) scheduler built on structured representation learning and aggregation. ReLA first learns diverse representations from s",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "In Search of Grandmother Cells: Tracing Interpretable Neurons in Tabular Representations",
      "link": "https://arxiv.org/abs/2601.03657",
      "summary": "arXiv:2601.03657v1 Announce Type: cross \nAbstract: Foundation models are powerful yet often opaque in their decision-making. A topic of continued interest in both neuroscience and artificial intelligence is whether some neurons behave like grandmother cells, i.e., neurons that are inherently interpretable because they exclusively respond to single concepts. In this work, we propose two information-theoretic measures that quantify the neuronal saliency and selectivity for single concepts. We appl",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Group and Exclusive Sparse Regularization-based Continual Learning of CNNs",
      "link": "https://arxiv.org/abs/2601.03658",
      "summary": "arXiv:2601.03658v1 Announce Type: cross \nAbstract: We present a regularization-based approach for continual learning (CL) of fixed capacity convolutional neural networks (CNN) that does not suffer from the problem of catastrophic forgetting when learning multiple tasks sequentially. This method referred to as Group and Exclusive Sparsity based Continual Learning (GESCL) avoids forgetting of previous tasks by ensuring the stability of the CNN via a stability regularization term, which prevents fi",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AMIR-GRPO: Inducing Implicit Preference Signals into GRPO",
      "link": "https://arxiv.org/abs/2601.03661",
      "summary": "arXiv:2601.03661v1 Announce Type: cross \nAbstract: Reinforcement learning has become the primary paradigm for aligning large language models (LLMs) on complex reasoning tasks, with group relative policy optimization (GRPO) widely used in large-scale post-training. However, GRPO faces structural limitations in reasoning-heavy settings: sequence-level advantage normalization introduces systematic length bias, penalties for low-quality trajectories are diluted, and the scalar objective discards ric",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings",
      "link": "https://arxiv.org/abs/2601.03666",
      "summary": "arXiv:2601.03666v1 Announce Type: cross \nAbstract: Modern information systems often involve different types of items, e.g., a text query, an image, a video clip, or an audio segment. This motivates omni-modal embedding models that map heterogeneous modalities into a shared space for direct comparison. However, most recent omni-modal embeddings still rely heavily on implicit alignment inherited from pretrained vision-language model (VLM) backbones. In practice, this causes three common issues: (i",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Discontinuous Galerkin finite element operator network for solving non-smooth PDEs",
      "link": "https://arxiv.org/abs/2601.03668",
      "summary": "arXiv:2601.03668v1 Announce Type: cross \nAbstract: We introduce Discontinuous Galerkin Finite Element Operator Network (DG--FEONet), a data-free operator learning framework that combines the strengths of the discontinuous Galerkin (DG) method with neural networks to solve parametric partial differential equations (PDEs) with discontinuous coefficients and non-smooth solutions. Unlike traditional operator learning models such as DeepONet and Fourier Neural Operator, which require large paired dat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Disentangling Aleatoric and Epistemic Uncertainty in Physics-Informed Neural Networks. Application to Insulation Material Degradation Prognostics",
      "link": "https://arxiv.org/abs/2601.03673",
      "summary": "arXiv:2601.03673v1 Announce Type: cross \nAbstract: Physics-Informed Neural Networks (PINNs) provide a framework for integrating physical laws with data. However, their application to Prognostics and Health Management (PHM) remains constrained by the limited uncertainty quantification (UQ) capabilities. Most existing PINN-based prognostics approaches are deterministic or account only for epistemic uncertainty, limiting their suitability for risk-aware decision-making. This work introduces a heter",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Towards Compositional Generalization of LLMs via Skill Taxonomy Guided Data Synthesis",
      "link": "https://arxiv.org/abs/2601.03676",
      "summary": "arXiv:2601.03676v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) and agent-based systems often struggle with compositional generalization due to a data bottleneck in which complex skill combinations follow a long-tailed, power-law distribution, limiting both instruction-following performance and generalization in agent-centric tasks. To address this challenge, we propose STEPS, a Skill Taxonomy guided Entropy-based Post-training data Synthesis framework for generating compositiona",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "From Implicit to Explicit: Token-Efficient Logical Supervision for Mathematical Reasoning in LLMs",
      "link": "https://arxiv.org/abs/2601.03682",
      "summary": "arXiv:2601.03682v1 Announce Type: cross \nAbstract: Recent studies reveal that large language models (LLMs) exhibit limited logical reasoning abilities in mathematical problem-solving, instead often relying on pattern-matching and memorization. We systematically analyze this limitation, focusing on logical relationship understanding, which is a core capability underlying genuine logical reasoning, and reveal that errors related to this capability account for over 90\\% of incorrect predictions, wi",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Pre-trained Reaction Embedding Descriptor Capturing Bond Transformation Patterns",
      "link": "https://arxiv.org/abs/2601.03689",
      "summary": "arXiv:2601.03689v1 Announce Type: cross \nAbstract: With the rise of data-driven reaction prediction models, effective reaction descriptors are crucial for bridging the gap between real-world chemistry and digital representations. However, general-purpose, reaction-wise descriptors remain scarce. This study introduces RXNEmb, a novel reaction-level descriptor derived from RXNGraphormer, a model pre-trained to distinguish real reactions from fictitious ones with erroneous bond changes, thereby lea",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Can AI Chatbots Provide Coaching in Engineering? Beyond Information Processing Toward Mastery",
      "link": "https://arxiv.org/abs/2601.03693",
      "summary": "arXiv:2601.03693v1 Announce Type: cross \nAbstract: Engineering education faces a double disruption: traditional apprenticeship models that cultivated judgment and tacit skill are eroding, just as generative AI emerges as an informal coaching partner. This convergence rekindles long-standing questions in the philosophy of AI and cognition about the limits of computation, the nature of embodied rationality, and the distinction between information processing and wisdom. Building on this rich intell",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ADEPT: Adaptive Dynamic Early-Exit Process for Transformers",
      "link": "https://arxiv.org/abs/2601.03700",
      "summary": "arXiv:2601.03700v1 Announce Type: cross \nAbstract: The inference of large language models imposes significant computational workloads, often requiring the processing of billions of parameters. Although early-exit strategies have proven effective in reducing computational demands by halting inference earlier, they apply either to only the first token in the generation phase or at the prompt level in the prefill phase. Thus, the Key-Value (KV) cache for skipped layers remains a bottleneck for subs",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Inference Attacks Against Graph Generative Diffusion Models",
      "link": "https://arxiv.org/abs/2601.03701",
      "summary": "arXiv:2601.03701v1 Announce Type: cross \nAbstract: Graph generative diffusion models have recently emerged as a powerful paradigm for generating complex graph structures, effectively capturing intricate dependencies and relationships within graph data. However, the privacy risks associated with these models remain largely unexplored. In this paper, we investigate information leakage in such models through three types of black-box inference attacks. First, we design a graph reconstruction attack,",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "TreeAdv: Tree-Structured Advantage Redistribution for Group-Based RL",
      "link": "https://arxiv.org/abs/2601.03703",
      "summary": "arXiv:2601.03703v1 Announce Type: cross \nAbstract: Reinforcement learning with group-based objectives, such as Group Relative Policy Optimization (GRPO), is a common framework for aligning large language models on complex reasoning tasks. However, standard GRPO treats each rollout trajectory as an independent flat sequence and assigns a single sequence-level advantage to all tokens, which leads to sample inefficiency and a length bias toward verbose, redundant chains of thought without improving",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Investigating Knowledge Distillation Through Neural Networks for Protein Binding Affinity Prediction",
      "link": "https://arxiv.org/abs/2601.03704",
      "summary": "arXiv:2601.03704v1 Announce Type: cross \nAbstract: The trade-off between predictive accuracy and data availability makes it difficult to predict protein--protein binding affinity accurately. The lack of experimentally resolved protein structures limits the performance of structure-based machine learning models, which generally outperform sequence-based methods. In order to overcome this constraint, we suggest a regression framework based on knowledge distillation that uses protein structural dat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MHRC-Bench: A Multilingual Hardware Repository-Level Code Completion benchmark",
      "link": "https://arxiv.org/abs/2601.03708",
      "summary": "arXiv:2601.03708v1 Announce Type: cross \nAbstract: Large language models (LLMs) have achieved strong performance on code completion tasks in general-purpose programming languages. However, existing repository-level code completion benchmarks focus almost exclusively on software code and largely overlook hardware description languages. In this work, we present \\textbf{MHRC-Bench}, consisting of \\textbf{MHRC-Bench-Train} and \\textbf{MHRC-Bench-Eval}, the first benchmark designed for multilingual h",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Power of 10: New Rules for the Digital World",
      "link": "https://arxiv.org/abs/2601.03709",
      "summary": "arXiv:2601.03709v1 Announce Type: cross \nAbstract: As artificial intelligence rapidly advances, society is increasingly captivated by promises of superhuman machines and seamless digital futures. Yet these visions often obscure mounting social, ethical, and psychological concerns tied to pervasive digital technologies - from surveillance to mental health crises. This article argues that a guiding ethos is urgently needed to navigate these transformations. Inspired by the lasting influence of the",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "R$^3$L: Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification",
      "link": "https://arxiv.org/abs/2601.03715",
      "summary": "arXiv:2601.03715v1 Announce Type: cross \nAbstract: Reinforcement learning drives recent advances in LLM reasoning and agentic capabilities, yet current approaches struggle with both exploration and exploitation. Exploration suffers from low success rates on difficult tasks and high costs of repeated rollouts from scratch. Exploitation suffers from coarse credit assignment and training instability: Trajectory-level rewards penalize valid prefixes for later errors, and failure-dominated groups ove",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CSMCIR: CoT-Enhanced Symmetric Alignment with Memory Bank for Composed Image Retrieval",
      "link": "https://arxiv.org/abs/2601.03728",
      "summary": "arXiv:2601.03728v1 Announce Type: cross \nAbstract: Composed Image Retrieval (CIR) enables users to search for target images using both a reference image and manipulation text, offering substantial advantages over single-modality retrieval systems. However, existing CIR methods suffer from representation space fragmentation: queries and targets comprise heterogeneous modalities and are processed by distinct encoders, forcing models to bridge misaligned representation spaces only through post-hoc ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "From Laboratory to Real-World Applications: Benchmarking Agentic Code Reasoning at the Repository Level",
      "link": "https://arxiv.org/abs/2601.03731",
      "summary": "arXiv:2601.03731v1 Announce Type: cross \nAbstract: As large language models (LLMs) evolve into autonomous agents, evaluating repository-level reasoning, the ability to maintain logical consistency across massive, real-world, interdependent file systems, has become critical. Current benchmarks typically fluctuate between isolated code snippets and black-box evaluations. We present RepoReason, a white-box diagnostic benchmark centered on abductive assertion verification. To eliminate memorization ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "RadDiff: Describing Differences in Radiology Image Sets with Natural Language",
      "link": "https://arxiv.org/abs/2601.03733",
      "summary": "arXiv:2601.03733v1 Announce Type: cross \nAbstract: Understanding how two radiology image sets differ is critical for generating clinical insights and for interpreting medical AI systems. We introduce RadDiff, a multimodal agentic system that performs radiologist-style comparative reasoning to describe clinically meaningful differences between paired radiology studies. RadDiff builds on a proposer-ranker framework from VisDiff, and incorporates four innovations inspired by real diagnostic workflo",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "O-Researcher: An Open Ended Deep Research Model via Multi-Agent Distillation and Agentic RL",
      "link": "https://arxiv.org/abs/2601.03743",
      "summary": "arXiv:2601.03743v1 Announce Type: cross \nAbstract: The performance gap between closed-source and open-source large language models (LLMs) is largely attributed to disparities in access to high-quality training data. To bridge this gap, we introduce a novel framework for the automated synthesis of sophisticated, research-grade instructional data. Our approach centers on a multi-agent workflow where collaborative AI agents simulate complex tool-integrated reasoning to generate diverse and high-fid",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Bridging OLAP and RAG: A Multidimensional Approach to the Design of Corpus Partitioning",
      "link": "https://arxiv.org/abs/2601.03748",
      "summary": "arXiv:2601.03748v1 Announce Type: cross \nAbstract: Retrieval-Augmented Generation (RAG) systems are increasingly deployed on large-scale document collections, often comprising millions of documents and tens of millions of text chunks. In industrial-scale retrieval platforms, scalability is typically addressed through horizontal sharding and a combination of Approximate Nearest-Neighbor search, hybrid indexing, and optimized metadata filtering. Although effective from an efficiency perspective, t",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Evaluation of Multilingual LLMs Personalized Text Generation Capabilities Targeting Groups and Social-Media Platforms",
      "link": "https://arxiv.org/abs/2601.03752",
      "summary": "arXiv:2601.03752v1 Announce Type: cross \nAbstract: Capabilities of large language models to generate multilingual coherent text have continuously enhanced in recent years, which opens concerns about their potential misuse. Previous research has shown that they can be misused for generation of personalized disinformation in multiple languages. It has also been observed that personalization negatively affects detectability of machine-generated texts; however, this has been studied in the English l",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Learning Shrinks the Hard Tail: Training-Dependent Inference Scaling in a Solvable Linear Model",
      "link": "https://arxiv.org/abs/2601.03764",
      "summary": "arXiv:2601.03764v1 Announce Type: cross \nAbstract: We analyze neural scaling laws in a solvable model of last-layer fine-tuning where targets have intrinsic, instance-heterogeneous difficulty. In our Latent Instance Difficulty (LID) model, each input's target variance is governed by a latent ``precision'' drawn from a heavy-tailed distribution. While generalization loss recovers standard scaling laws, our main contribution connects this to inference. The pass@$k$ failure rate exhibits a power-la",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Scalable Machine Learning Force Fields for Macromolecular Systems Through Long-Range Aware Message Passing",
      "link": "https://arxiv.org/abs/2601.03774",
      "summary": "arXiv:2601.03774v1 Announce Type: cross \nAbstract: Machine learning force fields (MLFFs) have revolutionized molecular simulations by providing quantum mechanical accuracy at the speed of molecular mechanical computations. However, a fundamental reliance of these models on fixed-cutoff architectures limits their applicability to macromolecular systems where long-range interactions dominate. We demonstrate that this locality constraint causes force prediction errors to scale monotonically with sy",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation",
      "link": "https://arxiv.org/abs/2601.03782",
      "summary": "arXiv:2601.03782v1 Announce Type: cross \nAbstract: Humans anticipate, from a glance and a contemplated action of their bodies, how the 3D world will respond, a capability that is equally vital for robotic manipulation. We introduce PointWorld, a large pre-trained 3D world model that unifies state and action in a shared 3D space as 3D point flows: given one or few RGB-D images and a sequence of low-level robot action commands, PointWorld forecasts per-pixel displacements in 3D that respond to the",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents",
      "link": "https://arxiv.org/abs/2601.03785",
      "summary": "arXiv:2601.03785v1 Announce Type: cross \nAbstract: Human-agent dialogues often exhibit topic continuity-a stable thematic frame that evolves through temporally adjacent exchanges-yet most large language model (LLM) agent memory systems fail to preserve it. Existing designs follow a fragmentation-compensation paradigm: they first break dialogue streams into isolated utterances for storage, then attempt to restore coherence via embedding-based retrieval. This process irreversibly damages narrative",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Criminal Liability of Generative Artificial Intelligence Providers for User-Generated Child Sexual Abuse Material",
      "link": "https://arxiv.org/abs/2601.03788",
      "summary": "arXiv:2601.03788v1 Announce Type: cross \nAbstract: The development of more powerful Generative Artificial Intelligence (GenAI) has expanded its capabilities and the variety of outputs. This has introduced significant legal challenges, including gray areas in various legal systems, such as the assessment of criminal liability for those responsible for these models. Therefore, we conducted a multidisciplinary study utilizing the statutory interpretation of relevant German laws, which, in conjuncti",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "NeoAMT: Neologism-Aware Agentic Machine Translation with Reinforcement Learning",
      "link": "https://arxiv.org/abs/2601.03790",
      "summary": "arXiv:2601.03790v1 Announce Type: cross \nAbstract: Neologism-aware machine translation aims to translate source sentences containing neologisms into target languages. This field remains underexplored compared with general machine translation (MT). In this paper, we propose an agentic framework, NeoAMT, for neologism-aware machine translation using a Wiktionary search tool. Specifically, we first create a new dataset for neologism-aware machine translation and develop a search tool based on Wikti",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Do LLMs Really Memorize Personally Identifiable Information? Revisiting PII Leakage with a Cue-Controlled Memorization Framework",
      "link": "https://arxiv.org/abs/2601.03791",
      "summary": "arXiv:2601.03791v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) have been reported to \"leak\" Personally Identifiable Information (PII), with successful PII reconstruction often interpreted as evidence of memorization. We propose a principled revision of memorization evaluation for LLMs, arguing that PII leakage should be evaluated under low lexical cue conditions, where target PII cannot be reconstructed through prompt-induced generalization or pattern completion. We formalize Cu",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An Algorithmic Framework for Systematic Literature Reviews: A Case Study for Financial Narratives",
      "link": "https://arxiv.org/abs/2601.03794",
      "summary": "arXiv:2601.03794v1 Announce Type: cross \nAbstract: This paper introduces an algorithmic framework for conducting systematic literature reviews (SLRs), designed to improve efficiency, reproducibility, and selection quality assessment in the literature review process. The proposed method integrates Natural Language Processing (NLP) techniques, clustering algorithms, and interpretability tools to automate and structure the selection and analysis of academic publications. The framework is applied to",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Where meaning lives: Layer-wise accessibility of psycholinguistic features in encoder and decoder language models",
      "link": "https://arxiv.org/abs/2601.03798",
      "summary": "arXiv:2601.03798v1 Announce Type: cross \nAbstract: Understanding where transformer language models encode psychologically meaningful aspects of meaning is essential for both theory and practice. We conduct a systematic layer-wise probing study of 58 psycholinguistic features across 10 transformer models, spanning encoder-only and decoder-only architectures, and compare three embedding extraction methods. We find that apparent localization of meaning is strongly method-dependent: contextualized e",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AI Generated Text Detection",
      "link": "https://arxiv.org/abs/2601.03812",
      "summary": "arXiv:2601.03812v1 Announce Type: cross \nAbstract: The rapid development of large language models has led to an increase in AI-generated text, with students increasingly using LLM-generated content as their own work, which violates academic integrity. This paper presents an evaluation of AI text detection methods, including both traditional machine learning models and transformer-based architectures. We utilize two datasets, HC3 and DAIGT v2, to build a unified benchmark and apply a topic-based ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "IDESplat: Iterative Depth Probability Estimation for Generalizable 3D Gaussian Splatting",
      "link": "https://arxiv.org/abs/2601.03824",
      "summary": "arXiv:2601.03824v1 Announce Type: cross \nAbstract: Generalizable 3D Gaussian Splatting aims to directly predict Gaussian parameters using a feed-forward network for scene reconstruction. Among these parameters, Gaussian means are particularly difficult to predict, so depth is usually estimated first and then unprojected to obtain the Gaussian sphere centers. Existing methods typically rely solely on a single warp to estimate depth probability, which hinders their ability to fully leverage cross-",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Logic Tensor Network-Enhanced Generative Adversarial Network",
      "link": "https://arxiv.org/abs/2601.03839",
      "summary": "arXiv:2601.03839v1 Announce Type: cross \nAbstract: In this paper, we introduce Logic Tensor Network-Enhanced Generative Adversarial Network (LTN-GAN), a novel framework that enhances Generative Adversarial Networks (GANs) by incorporating Logic Tensor Networks (LTNs) to enforce domain-specific logical constraints during the sample generation process. Although GANs have shown remarkable success in generating realistic data, they often lack mechanisms to incorporate prior knowledge or enforce logi",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "On the Trap Space Semantics of Normal Logic Programs",
      "link": "https://arxiv.org/abs/2601.03842",
      "summary": "arXiv:2601.03842v1 Announce Type: cross \nAbstract: The logical semantics of normal logic programs has traditionally been based on the notions of Clark's completion and two-valued or three-valued canonical models, including supported, stable, regular, and well-founded models. Two-valued interpretations can also be seen as states evolving under a program's update operator, producing a transition graph whose fixed points and cycles capture stable and oscillatory behaviors, respectively. We refer to",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents",
      "link": "https://arxiv.org/abs/2601.03846",
      "summary": "arXiv:2601.03846v1 Announce Type: cross \nAbstract: LLMs-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit communication, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert communication, relying on indirect or non-linguistic signals embedded in their actions rather th",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Implementing the First-Order Logic of Here and There",
      "link": "https://arxiv.org/abs/2601.03848",
      "summary": "arXiv:2601.03848v1 Announce Type: cross \nAbstract: We present automated theorem provers for the first-order logic of here and there (HT). They are based on a native sequent calculus for the logic of HT and an axiomatic embedding of the logic of HT into intuitionistic logic. The analytic proof search in the sequent calculus is optimized by using free variables and skolemization. The embedding is used in combination with sequent, tableau and connection calculi for intuitionistic first-order logic.",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "What Matters For Safety Alignment?",
      "link": "https://arxiv.org/abs/2601.03868",
      "summary": "arXiv:2601.03868v1 Announce Type: cross \nAbstract: This paper presents a comprehensive empirical study on the safety alignment capabilities. We evaluate what matters for safety alignment in LLMs and LRMs to provide essential insights for developing more secure and reliable AI systems. We systematically investigate and compare the influence of six critical intrinsic model characteristics and three external attack techniques. Our large-scale evaluation is conducted using 32 recent, popular LLMs an",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Women Worry, Men Adopt: How Gendered Perceptions Shape the Use of Generative AI",
      "link": "https://arxiv.org/abs/2601.03880",
      "summary": "arXiv:2601.03880v1 Announce Type: cross \nAbstract: Generative artificial intelligence (GenAI) is diffusing rapidly, yet its adoption is strikingly unequal. Using nationally representative UK survey data from 2023 to 2024, we show that women adopt GenAI substantially less often than men because they perceive its societal risks differently. We construct a composite index capturing concerns about mental health, privacy, climate impact, and labor market disruption. This index explains between 9 and ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FLNet: Flood-Induced Agriculture Damage Assessment using Super Resolution of Satellite Images",
      "link": "https://arxiv.org/abs/2601.03884",
      "summary": "arXiv:2601.03884v1 Announce Type: cross \nAbstract: Distributing government relief efforts after a flood is challenging. In India, the crops are widely affected by floods; therefore, making rapid and accurate crop damage assessment is crucial for effective post-disaster agricultural management. Traditional manual surveys are slow and biased, while current satellite-based methods face challenges like cloud cover and low spatial resolution. Therefore, to bridge this gap, this paper introduced FLNet",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "IndexTTS 2.5 Technical Report",
      "link": "https://arxiv.org/abs/2601.03888",
      "summary": "arXiv:2601.03888v2 Announce Type: cross \nAbstract: In prior work, we introduced IndexTTS 2, a zero-shot neural text-to-speech foundation model comprising two core components: a transformer-based Text-to-Semantic (T2S) module and a non-autoregressive Semantic-to-Mel (S2M) module, which together enable faithful emotion replication and establish the first autoregressive duration-controllable generative paradigm. Building upon this, we present IndexTTS 2.5, which significantly enhances multilingual ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Spectral Manifold Regularization for Stable and Modular Routing in Deep MoE Architectures",
      "link": "https://arxiv.org/abs/2601.03889",
      "summary": "arXiv:2601.03889v1 Announce Type: cross \nAbstract: Mixture of Experts (MoE) architectures enable efficient scaling of neural networks but suffer from expert collapse, where routing converges to a few dominant experts. This reduces model capacity and causes catastrophic interference during adaptation. We propose the Spectrally-Regularized Mixture of Experts (SR-MoE), which imposes geometric constraints on the routing manifold to enforce structural modularity. Our method uses dual regularization: ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Adaptive-Boundary-Clipping GRPO: Ensuring Bounded Ratios for Stable and Generalizable Training",
      "link": "https://arxiv.org/abs/2601.03895",
      "summary": "arXiv:2601.03895v1 Announce Type: cross \nAbstract: Group Relative Policy Optimization (GRPO) has emerged as a popular algorithm for reinforcement learning with large language models (LLMs). However, upon analyzing its clipping mechanism, we argue that it is suboptimal in certain scenarios. With appropriate modifications, GRPO can be significantly enhanced to improve both flexibility and generalization. To this end, we propose Adaptive-Boundary-Clipping GRPO (ABC-GRPO), an asymmetric and adaptive",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An Algebraic Representation Theorem for Linear GENEOs in Geometric Machine Learning",
      "link": "https://arxiv.org/abs/2601.03910",
      "summary": "arXiv:2601.03910v1 Announce Type: cross \nAbstract: Geometric and Topological Deep Learning are rapidly growing research areas that enhance machine learning through the use of geometric and topological structures. Within this framework, Group Equivariant Non-Expansive Operators (GENEOs) have emerged as a powerful class of operators for encoding symmetries and designing efficient, interpretable neural architectures. Originally introduced in Topological Data Analysis, GENEOs have since found applic",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Gap Between Decision Trees and Neural Networks",
      "link": "https://arxiv.org/abs/2601.03919",
      "summary": "arXiv:2601.03919v2 Announce Type: cross \nAbstract: We study when geometric simplicity of decision boundaries, used here as a notion of interpretability, can conflict with accurate approximation of axis-aligned decision trees by shallow neural networks. Decision trees induce rule-based, axis-aligned decision regions (finite unions of boxes), whereas shallow ReLU networks are typically trained as score models whose predictions are obtained by thresholding. We analyze the infinite-width, bounded-no",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection",
      "link": "https://arxiv.org/abs/2601.03928",
      "summary": "arXiv:2601.03928v1 Announce Type: cross \nAbstract: Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this w",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Bayes-PD: Exploring a Sequence to Binding Bayesian Neural Network model trained on Phage Display data",
      "link": "https://arxiv.org/abs/2601.03930",
      "summary": "arXiv:2601.03930v1 Announce Type: cross \nAbstract: Phage display is a powerful laboratory technique used to study the interactions between proteins and other molecules, whether other proteins, peptides, DNA or RNA. The under-utilisation of this data in conjunction with deep learning models for protein design may be attributed to; high experimental noise levels; the complex nature of data pre-processing; and difficulty interpreting these experimental results. In this work, we propose a novel appr",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FOREVER: Forgetting Curve-Inspired Memory Replay for Language Model Continual Learning",
      "link": "https://arxiv.org/abs/2601.03938",
      "summary": "arXiv:2601.03938v1 Announce Type: cross \nAbstract: Continual learning (CL) for large language models (LLMs) aims to enable sequential knowledge acquisition without catastrophic forgetting. Memory replay methods are widely used for their practicality and effectiveness, but most rely on fixed, step-based heuristics that often misalign with the model's actual learning progress, since identical training steps can result in varying degrees of parameter change. Motivated by recent findings that LLM fo",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Large-Scale Aspect-Based Sentiment Analysis with Reasoning-Infused LLMs",
      "link": "https://arxiv.org/abs/2601.03940",
      "summary": "arXiv:2601.03940v1 Announce Type: cross \nAbstract: We introduce Arctic-ABSA, a collection of powerful models for real-life aspect-based sentiment analysis (ABSA). Our models are tailored to commercial needs, trained on a large corpus of public data alongside carefully generated synthetic data, resulting in a dataset 20 times larger than SemEval14. We extend typical ABSA models by expanding the number of sentiment classes from the standard three (positive, negative, neutral) to five, adding mixed",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems",
      "link": "https://arxiv.org/abs/2601.03992",
      "summary": "arXiv:2601.03992v1 Announce Type: cross \nAbstract: Mixture-of-Experts (MoE) models facilitate edge deployment by decoupling model capacity from active computation, yet their large memory footprint drives the need for GPU systems with near-data processing (NDP) capabilities that offload experts to dedicated processing units. However, deploying MoE models on such edge-based GPU-NDP systems faces three critical challenges: 1) severe load imbalance across NDP units due to non-uniform expert selectio",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "HoneyTrap: Deceiving Large Language Model Attackers to Honeypot Traps with Resilient Multi-Agent Defense",
      "link": "https://arxiv.org/abs/2601.04034",
      "summary": "arXiv:2601.04034v1 Announce Type: cross \nAbstract: Jailbreak attacks pose significant threats to large language models (LLMs), enabling attackers to bypass safeguards. However, existing reactive defense approaches struggle to keep up with the rapidly evolving multi-turn jailbreaks, where attackers continuously deepen their attacks to exploit vulnerabilities. To address this critical challenge, we propose HoneyTrap, a novel deceptive LLM defense framework leveraging collaborative defenders to cou",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models",
      "link": "https://arxiv.org/abs/2601.04068",
      "summary": "arXiv:2601.04068v2 Announce Type: cross \nAbstract: Aligning text-to-video diffusion models with human preferences is crucial for generating high-quality videos. Existing Direct Preference Otimization (DPO) methods rely on multi-sample ranking and task-specific critic models, which is inefficient and often yields ambiguous global supervision. To address these limitations, we propose LocalDPO, a novel post-training framework that constructs localized preference pairs from real videos and optimizes",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Analyzing Reasoning Consistency in Large Multimodal Models under Cross-Modal Conflicts",
      "link": "https://arxiv.org/abs/2601.04073",
      "summary": "arXiv:2601.04073v1 Announce Type: cross \nAbstract: Large Multimodal Models (LMMs) have demonstrated impressive capabilities in video reasoning via Chain-of-Thought (CoT). However, the robustness of their reasoning chains remains questionable. In this paper, we identify a critical failure mode termed textual inertia, where once a textual hallucination occurs in the thinking process, models tend to blindly adhere to the erroneous text while neglecting conflicting visual evidence. To systematically",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CSSG: Measuring Code Similarity with Semantic Graphs",
      "link": "https://arxiv.org/abs/2601.04085",
      "summary": "arXiv:2601.04085v1 Announce Type: cross \nAbstract: Existing code similarity metrics, such as BLEU, CodeBLEU, and TSED, largely rely on surface-level string overlap or abstract syntax tree structures, and often fail to capture deeper semantic relationships between programs.We propose CSSG (Code Similarity using Semantic Graphs), a novel metric that leverages program dependence graphs to explicitly model control dependencies and variable interactions, providing a semantics-aware representation of ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Layer-wise Positional Bias in Short-Context Language Modeling",
      "link": "https://arxiv.org/abs/2601.04098",
      "summary": "arXiv:2601.04098v1 Announce Type: cross \nAbstract: Language models often show a preference for using information from specific positions in the input regardless of semantic relevance. While positional bias has been studied in various contexts, from attention sinks to task performance degradation in long-context settings, prior work has not established how these biases evolve across individual layers and input positions, or how they vary independent of task complexity. We introduce an attribution",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Quantifying the Impact of Modules and Their Interactions in the PSO-X Framework",
      "link": "https://arxiv.org/abs/2601.04100",
      "summary": "arXiv:2601.04100v1 Announce Type: cross \nAbstract: The PSO-X framework incorporates dozens of modules that have been proposed for solving single-objective continuous optimization problems using particle swarm optimization. While modular frameworks enable users to automatically generate and configure algorithms tailored to specific optimization problems, the complexity of this process increases with the number of modules in the framework and the degrees of freedom defined for their interaction. U",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training",
      "link": "https://arxiv.org/abs/2601.04126",
      "summary": "arXiv:2601.04126v2 Announce Type: cross \nAbstract: GUI agents that interact with graphical interfaces on behalf of users represent a promising direction for practical AI assistants. However, training such agents is hindered by the scarcity of suitable environments. We present InfiniteWeb, a system that automatically generates functional web environments at scale for GUI agent training. While LLMs perform well on generating a single webpage, building a realistic and functional website with many i",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Pixel-Wise Multimodal Contrastive Learning for Remote Sensing Images",
      "link": "https://arxiv.org/abs/2601.04127",
      "summary": "arXiv:2601.04127v1 Announce Type: cross \nAbstract: Satellites continuously generate massive volumes of data, particularly for Earth observation, including satellite image time series (SITS). However, most deep learning models are designed to process either entire images or complete time series sequences to extract meaningful features for downstream tasks. In this study, we propose a novel multimodal approach that leverages pixel-wise two-dimensional (2D) representations to encode visual property",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models",
      "link": "https://arxiv.org/abs/2601.04131",
      "summary": "arXiv:2601.04131v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) encode vast amounts of parametric knowledge during pre-training. As world knowledge evolves, effective deployment increasingly depends on their ability to faithfully follow externally retrieved context. When such evidence conflicts with the model's internal knowledge, LLMs often default to memorized facts, producing unfaithful outputs. In this work, we introduce ContextFocus, a lightweight activation steering approac",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test",
      "link": "https://arxiv.org/abs/2601.04137",
      "summary": "arXiv:2601.04137v1 Announce Type: cross \nAbstract: As world models gain momentum in Embodied AI, an increasing number of works explore using video foundation models as predictive world models for downstream embodied tasks like 3D prediction or interactive generation. However, before exploring these downstream tasks, video foundation models still have two critical questions unanswered: (1) whether their generative generalization is sufficient to maintain perceptual fidelity in the eyes of human o",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Klear: Unified Multi-Task Audio-Video Joint Generation",
      "link": "https://arxiv.org/abs/2601.04151",
      "summary": "arXiv:2601.04151v1 Announce Type: cross \nAbstract: Audio-video joint generation has progressed rapidly, yet substantial challenges still remain. Non-commercial approaches still suffer audio-visual asynchrony, poor lip-speech alignment, and unimodal degradation, which can be stemmed from weak audio-visual correspondence modeling, limited generalization, and scarce high-quality dense-caption data. To address these issues, we introduce Klear and delve into three axes--model architecture, training s",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Clinical Data Goes MEDS? Let's OWL make sense of it",
      "link": "https://arxiv.org/abs/2601.04164",
      "summary": "arXiv:2601.04164v1 Announce Type: cross \nAbstract: The application of machine learning on healthcare data is often hindered by the lack of standardized and semantically explicit representation, leading to limited interoperability and reproducibility across datasets and experiments. The Medical Event Data Standard (MEDS) addresses these issues by introducing a minimal, event-centric data model designed for reproducible machine-learning workflows from health data. However, MEDS is defined as a dat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Embedding Autonomous Agents in Resource-Constrained Robotic Platforms",
      "link": "https://arxiv.org/abs/2601.04191",
      "summary": "arXiv:2601.04191v1 Announce Type: cross \nAbstract: Many embedded devices operate under resource constraints and in dynamic environments, requiring local decision-making capabilities. Enabling devices to make independent decisions in such environments can improve the responsiveness of the system and reduce the dependence on constant external control. In this work, we integrate an autonomous agent, programmed using AgentSpeak, with a small two-wheeled robot that explores a maze using its own decis",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "F{\\AE}RDXEL: An Expert System for Danish Traffic Law",
      "link": "https://arxiv.org/abs/2410.03560",
      "summary": "arXiv:2410.03560v2 Announce Type: replace \nAbstract: We present F{\\AE}RDXEL, a tool for symbolic reasoning in the domain of Danish traffic law. F{\\AE}RDXEL combines techniques from logic programming with a novel interface that allows users to navigate through its reasoning process, thereby ensuring the system's explainability. Towards the goal of better understanding the value of F{\\AE}RDXEL, two evaluations of the system have been performed: (1) An empirical evaluation showing that for a select",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Imagining and building wise machines: The centrality of AI metacognition",
      "link": "https://arxiv.org/abs/2411.02478",
      "summary": "arXiv:2411.02478v4 Announce Type: replace \nAbstract: Although AI has become increasingly smart, its wisdom has not kept pace. In this article, we examine what is known about human wisdom and sketch a vision of its AI counterpart. We analyze human wisdom as a set of strategies for solving intractable problems-those outside the scope of analytic techniques-including both object-level strategies like heuristics [for managing problems] and metacognitive strategies like intellectual humility, perspec",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning",
      "link": "https://arxiv.org/abs/2501.14540",
      "summary": "arXiv:2501.14540v3 Announce Type: replace \nAbstract: A recent approach to neurosymbolic reasoning is to explicitly combine the strengths of large language models (LLMs) and symbolic solvers to tackle complex reasoning tasks. However, current approaches face significant limitations, including poor generalizability due to task-specific prompts, inefficiencies caused by the lack of separation between knowledge and queries, and restricted inferential capabilities. These shortcomings hinder their sca",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SPIO: Ensemble and Selective Strategies via LLM-Based Multi-Agent Planning in Automated Data Science",
      "link": "https://arxiv.org/abs/2503.23314",
      "summary": "arXiv:2503.23314v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have enabled dynamic reasoning in automated data analytics, yet recent multi-agent systems remain limited by rigid, single-path workflows that restrict strategic exploration and often lead to suboptimal outcomes. To overcome these limitations, we propose SPIO (Sequential Plan Integration and Optimization), a framework that replaces rigid workflows with adaptive, multi-path planning across four core modules: data pr",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Beyond Chemical QA: Evaluating LLM's Chemical Reasoning with Modular Chemical Operations",
      "link": "https://arxiv.org/abs/2505.21318",
      "summary": "arXiv:2505.21318v3 Announce Type: replace \nAbstract: While large language models (LLMs) with Chain-of-Thought (CoT) reasoning excel in mathematics and coding, their potential for systematic reasoning in chemistry, a domain demanding rigorous structural analysis for real-world tasks like drug design and reaction engineering, remains untapped. Current benchmarks focus on simple knowledge retrieval, neglecting step-by-step reasoning required for complex tasks such as molecular optimization and reac",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A framework for Conditional Reasoning in Answer Set Programming",
      "link": "https://arxiv.org/abs/2506.03997",
      "summary": "arXiv:2506.03997v3 Announce Type: replace \nAbstract: In this paper we introduce a Conditional Answer Set Programming framework (Conditional ASP) for the definition of conditional extensions of Answer Set Programming (ASP). The approach builds on a conditional logic with typicality, and on the combination of a conditional knowledge base with an ASP program, and allows for conditional reasoning over the answer sets of the program. The formalism relies on a multi-preferential semantics, and on the ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The ASP-based Nurse Scheduling System at the University of Yamanashi Hospital",
      "link": "https://arxiv.org/abs/2506.13600",
      "summary": "arXiv:2506.13600v2 Announce Type: replace \nAbstract: We present the design principles of a nurse scheduling system built using Answer Set Programming (ASP) and successfully deployed at the University of Yamanashi Hospital. Nurse scheduling is a complex optimization problem requiring the reconciliation of individual nurse preferences with hospital staffing needs across various wards. This involves balancing hard and soft constraints and the flexibility of interactive adjustments. While extensivel",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming",
      "link": "https://arxiv.org/abs/2506.19573",
      "summary": "arXiv:2506.19573v2 Announce Type: replace \nAbstract: Machine learning (ML) techniques play a pivotal role in high-stakes domains such as healthcare, where accurate predictions can greatly enhance decision-making. However, most high-performing methods such as neural networks and ensemble methods are often opaque, limiting trust and broader adoption. In parallel, symbolic methods like Answer Set Programming (ASP) offer the possibility of interpretable logical rules but do not always match the pred",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An ASP-Based Framework for MUSes",
      "link": "https://arxiv.org/abs/2507.03929",
      "summary": "arXiv:2507.03929v2 Announce Type: replace \nAbstract: Given an unsatisfiable formula, understanding the core reason for unsatisfiability is crucial in several applications. One effective way to capture this is through the minimal unsatisfiable subset (MUS), the subset-minimal set of clauses that remains unsatisfiable. Current research broadly focuses on two directions: (i) enumerating as many MUSes as possible within a given time limit, and (ii) counting the total number of MUSes for a given unsa",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "League of LLMs: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models",
      "link": "https://arxiv.org/abs/2507.22359",
      "summary": "arXiv:2507.22359v3 Announce Type: replace \nAbstract: Although large language models (LLMs) have shown exceptional capabilities across a wide range of tasks, reliable evaluation remains a critical challenge due to data contamination, opaque operation, and subjective preferences. To address these issues, we propose League of LLMs (LOL), a novel benchmark-free evaluation paradigm that organizes multiple LLMs into a self-governed league for multi-round mutual evaluation. LOL integrates four core cri",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools",
      "link": "https://arxiv.org/abs/2508.02110",
      "summary": "arXiv:2508.02110v2 Announce Type: replace \nAbstract: Large language model (LLM) agents have demonstrated remarkable capabilities in complex reasoning and decision-making by leveraging external tools. However, this tool-centric paradigm introduces a previously underexplored attack surface, where adversaries can manipulate tool metadata -- such as names, descriptions, and parameter schemas -- to influence agent behavior. We identify this as a new and stealthy threat surface that allows malicious t",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Answering the Unanswerable Is to Err Knowingly: Analyzing and Mitigating Abstention Failures in Large Reasoning Models",
      "link": "https://arxiv.org/abs/2508.18760",
      "summary": "arXiv:2508.18760v2 Announce Type: replace \nAbstract: Large reasoning models (LRMs) have shown remarkable progress on complex reasoning tasks. However, some questions posed to LRMs are inherently unanswerable, such as math problems lacking sufficient conditions. We find that LRMs continually fail to provide appropriate abstentions when confronted with these unanswerable questions. In this paper, we systematically analyze, investigate, and resolve this issue for trustworthy AI. We first conduct a ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents",
      "link": "https://arxiv.org/abs/2509.21799",
      "summary": "arXiv:2509.21799v3 Announce Type: replace \nAbstract: Graphical User Interface (GUI) agents aim to automate a wide spectrum of human tasks by emulating user interaction. Despite rapid advancements, current approaches are hindered by several critical challenges: data bottleneck in end-to-end training, high cost of delayed error detection, and risk of contradictory guidance. Inspired by the human cognitive loop of Thinking, Alignment, and Reflection, we present D-Artemis -- a novel deliberative fra",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Multiplayer Nash Preference Optimization",
      "link": "https://arxiv.org/abs/2509.23102",
      "summary": "arXiv:2509.23102v2 Announce Type: replace \nAbstract: Reinforcement learning from human feedback (RLHF) has emerged as the standard paradigm for aligning large language models with human preferences. However, reward-based methods built on the Bradley-Terry assumption struggle to capture the non-transitive and heterogeneous nature of real-world preferences. To address this, recent studies have reframed alignment as a two-player Nash game, giving rise to Nash learning from human feedback (NLHF). Wh",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Agentic Exploration of Physics Models",
      "link": "https://arxiv.org/abs/2509.24978",
      "summary": "arXiv:2509.24978v4 Announce Type: replace \nAbstract: The process of scientific discovery relies on an interplay of observations, analysis, and hypothesis generation. Machine learning is increasingly being adopted to address individual aspects of this process. However, it remains an open challenge to fully automate the heuristic, iterative loop required to discover the laws of an unknown system by exploring it through experiments and analysis, without tailoring the approach to the specifics of a ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search",
      "link": "https://arxiv.org/abs/2509.25454",
      "summary": "arXiv:2509.25454v3 Announce Type: replace \nAbstract: Although RLVR has become an essential component for developing advanced reasoning skills in language models, contemporary studies have documented training plateaus after thousands of optimization steps, i.e., notable decreases in performance gains despite increased computational investment. This limitation stems from the sparse exploration patterns inherent in current RLVR practices, where models rely on limited rollouts that often miss critic",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering",
      "link": "https://arxiv.org/abs/2510.04514",
      "summary": "arXiv:2510.04514v2 Announce Type: replace \nAbstract: Recent multimodal LLMs have shown promise in chart-based visual question answering, but their performance declines sharply on unannotated charts-those requiring precise visual interpretation rather than relying on textual shortcuts. To address this, we introduce ChartAgent, a novel agentic framework that explicitly performs visual reasoning directly within the chart's spatial domain. Unlike textual chain-of-thought reasoning, ChartAgent iterat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "When Identity Skews Debate: Anonymization for Bias-Reduced Multi-Agent Reasoning",
      "link": "https://arxiv.org/abs/2510.07517",
      "summary": "arXiv:2510.07517v4 Announce Type: replace \nAbstract: Multi-agent debate (MAD) aims to improve large language model (LLM) reasoning by letting multiple agents exchange answers and then aggregate their opinions. Yet recent studies reveal that agents are not neutral: they are prone to identity-driven sycophancy and self-bias, uncritically adopting a peer's view or stubbornly adhering to their own prior output, undermining the reliability of debate. In this work, we present the first principled fram",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ELAIPBench: A Benchmark for Expert-Level Artificial Intelligence Paper Understanding",
      "link": "https://arxiv.org/abs/2510.10549",
      "summary": "arXiv:2510.10549v2 Announce Type: replace \nAbstract: While large language models (LLMs) excel at many domain-specific tasks, their ability to deeply comprehend and reason about full-length academic papers remains underexplored. Existing benchmarks often fall short of capturing such depth, either due to surface-level question design or unreliable evaluation metrics. To address this gap, we introduce ELAIPBench, a benchmark curated by domain experts to evaluate LLMs' comprehension of artificial in",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Better Call CLAUSE: A Discrepancy Benchmark for Auditing LLMs Legal Reasoning Capabilities",
      "link": "https://arxiv.org/abs/2511.00340",
      "summary": "arXiv:2511.00340v2 Announce Type: replace \nAbstract: The rapid integration of large language models (LLMs) into high-stakes legal work has exposed a critical gap: no benchmark exists to systematically stress-test their reliability against the nuanced, adversarial, and often subtle flaws present in real-world contracts. To address this, we introduce CLAUSE, a first-of-its-kind benchmark designed to evaluate the fragility of an LLM's legal reasoning. We study the capabilities of LLMs to detect and",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Chain-of-Thought as a Lens: Evaluating Structured Reasoning Alignment between Human Preferences and Large Language Models",
      "link": "https://arxiv.org/abs/2511.06168",
      "summary": "arXiv:2511.06168v2 Announce Type: replace \nAbstract: This paper primarily demonstrate a method to quantitatively assess the alignment between multi-step, structured reasoning in large language models and human preferences. We introduce the Alignment Score, a semantic-level metric that compares a model-produced chain of thought traces with a human-preferred reference by constructing semantic-entropy-based matrices over intermediate steps and measuring their divergence. Our analysis shows that Ali",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Faithful-First Reasoning, Planning, and Acting for Multimodal LLMs",
      "link": "https://arxiv.org/abs/2511.08409",
      "summary": "arXiv:2511.08409v3 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLMs) frequently suffer from unfaithfulness, generating reasoning chains that drift from visual evidence or contradict final predictions. We propose Faithful-First Reasoning, Planning, and Acting (RPA) framework in which FaithEvi provides step-wise and chain-level supervision by evaluating the faithfulness of intermediate reasoning, and FaithAct uses these signals to plan and execute faithfulness-aware action",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Boosting In-Silicon Directed Evolution with Fine-Tuned Protein Language Model and Tree Search",
      "link": "https://arxiv.org/abs/2511.09900",
      "summary": "arXiv:2511.09900v4 Announce Type: replace \nAbstract: Protein evolution through amino acid mutations is a cornerstone of life sciences. Recent advances in protein language models have shown rich evolutionary patterns, offering unprecedented potential for in-silicon directed evolution. However, existing directed evolution methods largely rely on heuristic evolution strategies and have yet to efficiently integrate the transformative protein language models with advanced optimization techniques, suc",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response",
      "link": "https://arxiv.org/abs/2511.15755",
      "summary": "arXiv:2511.15755v2 Announce Type: replace \nAbstract: Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scen",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases",
      "link": "https://arxiv.org/abs/2512.16953",
      "summary": "arXiv:2512.16953v2 Announce Type: replace \nAbstract: Recognizing similarities among entities is central to both human cognition and computational intelligence. Within this broader landscape, Entity Set Expansion is one prominent task aimed at taking an initial set of (tuples of) entities and identifying additional ones that share relevant semantic properties with the former -- potentially repeating the process to form increasingly broader sets. However, this ``linear'' approach does not unveil t",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent",
      "link": "https://arxiv.org/abs/2512.21578",
      "summary": "arXiv:2512.21578v3 Announce Type: replace \nAbstract: We present the development and optimization of PayPal's Commerce Agent, powered by NEMO-4-PAYPAL, a multi-agent system designed to revolutionize agentic commerce on the PayPal platform. Through our strategic partnership with NVIDIA, we leveraged the NeMo Framework for LLM model fine-tuning to enhance agent performance. Specifically, we optimized the Search and Discovery agent by replacing our base model with a fine-tuned Nemotron small languag",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Monadic Context Engineering",
      "link": "https://arxiv.org/abs/2512.22431",
      "summary": "arXiv:2512.22431v2 Announce Type: replace \nAbstract: The proliferation of Large Language Models (LLMs) has catalyzed a shift towards autonomous agents capable of complex reasoning and tool use. However, current agent architectures are frequently constructed using imperative, ad hoc patterns. This results in brittle systems plagued by difficulties in state management, error handling, and concurrency. This paper introduces Monadic Context Engineering (MCE), a novel architectural paradigm leveragin",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning",
      "link": "https://arxiv.org/abs/2512.23412",
      "summary": "arXiv:2512.23412v2 Announce Type: replace \nAbstract: Traditional workflow-based agents exhibit limited intelligence when addressing real-world problems requiring tool invocation. Tool-integrated reasoning (TIR) agents capable of autonomous reasoning and tool invocation are rapidly emerging as a powerful approach for complex decision-making tasks involving multi-step interactions with external environments. In this work, we introduce MindWatcher, a TIR agent integrating interleaved thinking and m",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios",
      "link": "https://arxiv.org/abs/2601.01857",
      "summary": "arXiv:2601.01857v2 Announce Type: replace \nAbstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework gr",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations",
      "link": "https://arxiv.org/abs/2601.02071",
      "summary": "arXiv:2601.02071v2 Announce Type: replace \nAbstract: Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation chal",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "HAL: Inducing Human-likeness in LLMs with Alignment",
      "link": "https://arxiv.org/abs/2601.02813",
      "summary": "arXiv:2601.02813v2 Announce Type: replace \nAbstract: Conversational human-likeness plays a central role in human-AI interaction, yet it has remained difficult to define, measure, and optimize. As a result, improvements in human-like behavior are largely driven by scale or broad supervised training, rather than targeted alignment. We introduce Human Aligning LLMs (HAL), a framework for aligning language models to conversational human-likeness using an interpretable, data-driven reward. HAL derive",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Discovering the Representation Bottleneck of Graph Neural Networks",
      "link": "https://arxiv.org/abs/2205.07266",
      "summary": "arXiv:2205.07266v5 Announce Type: replace-cross \nAbstract: Graph neural networks (GNNs) rely mainly on the message-passing paradigm to propagate node features and build interactions, and different graph learning problems require different ranges of node interactions. In this work, we explore the capacity of GNNs to capture node interactions under contexts of different complexities. We discover that GNNs usually fail to capture the most informative kinds of interaction styles for diverse graph le",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Instructor-inspired Machine Learning for Robust Molecular Property Prediction",
      "link": "https://arxiv.org/abs/2304.03906",
      "summary": "arXiv:2304.03906v3 Announce Type: replace-cross \nAbstract: Machine learning catalyzes a revolution in chemical and biological science. However, its efficacy heavily depends on the availability of labeled data, and annotating biochemical data is extremely laborious. To surmount this data sparsity challenge, we present an instructive learning algorithm named InstructMol to measure pseudo-labels' reliability and help the target model leverage large-scale unlabeled data. InstructMol does not require",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Computing Universal Plans for Partially Observable Multi-Agent Routing Using Answer Set Programming",
      "link": "https://arxiv.org/abs/2305.16203",
      "summary": "arXiv:2305.16203v4 Announce Type: replace-cross \nAbstract: Multi-agent routing problems have gained significant attention recently due to their wide range of industrial applications, ranging from logistics warehouse automation to indoor service robots. Conventionally, they are modeled as classical planning problems. In this paper, we argue that it can be beneficial to formulate them as universal planning problems, particularly when the agents are autonomous entities and may encounter unforeseen ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Towards the Terminator Economy: Assessing Job Exposure to AI through LLMs",
      "link": "https://arxiv.org/abs/2407.19204",
      "summary": "arXiv:2407.19204v3 Announce Type: replace-cross \nAbstract: AI and related technologies are reshaping jobs and tasks, either by automating or augmenting human skills in the workplace. Many researchers have been working on estimating if and to what extent jobs and tasks are exposed to the risk of being automatized by AI-related technologies. Our work tackles this issue through a data-driven approach by: (i) developing a reproducible framework that uses cutting-edge open-source large language model",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Systematic Comparison between Extractive Self-Explanations and Human Rationales in Text Classification",
      "link": "https://arxiv.org/abs/2410.03296",
      "summary": "arXiv:2410.03296v3 Announce Type: replace-cross \nAbstract: Instruction-tuned LLMs are able to provide \\textit{an} explanation about their output to users by generating self-explanations, without requiring the application of complex interpretability techniques. In this paper, we analyse whether this ability results in a \\textit{good} explanation. We evaluate self-explanations in the form of input rationales with respect to their plausibility to humans. We study three text classification tasks: se",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An Overview of Prototype Formulations for Interpretable Deep Learning",
      "link": "https://arxiv.org/abs/2410.08925",
      "summary": "arXiv:2410.08925v4 Announce Type: replace-cross \nAbstract: Prototypical part networks offer interpretable alternatives to black-box deep learning models by learning visual prototypes for classification. This work provides a comprehensive analysis of prototype formulations, comparing point-based and probabilistic approaches in both Euclidean and hyperspherical latent spaces.\n  We introduce HyperPG, a probabilistic prototype representation using Gaussian distributions on hyperspheres. Experiments ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SSSD: Simply-Scalable Speculative Decoding",
      "link": "https://arxiv.org/abs/2411.05894",
      "summary": "arXiv:2411.05894v2 Announce Type: replace-cross \nAbstract: Speculative Decoding has emerged as a popular technique for accelerating inference in Large Language Models. However, most existing approaches yield only modest improvements in production serving systems. Methods that achieve substantial speedups typically rely on an additional trained draft model or auxiliary model components, increasing deployment and maintenance complexity. This added complexity reduces flexibility, particularly when ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Exploring Iterative Controllable Summarization with Large Language Models",
      "link": "https://arxiv.org/abs/2411.12460",
      "summary": "arXiv:2411.12460v3 Announce Type: replace-cross \nAbstract: Large language models (LLMs) have demonstrated remarkable performance in abstractive summarization tasks. However, their ability to precisely control summary attributes (e.g., length or topic) remains underexplored, limiting their adaptability to specific user preferences. In this paper, we systematically explore the controllability of LLMs. To this end, we revisit summary attribute measurements and introduce iterative evaluation metrics",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FedDUAL: A Dual-Strategy with Adaptive Loss and Dynamic Aggregation for Mitigating Data Heterogeneity in Federated Learning",
      "link": "https://arxiv.org/abs/2412.04416",
      "summary": "arXiv:2412.04416v2 Announce Type: replace-cross \nAbstract: Federated Learning (FL) marks a transformative approach to distributed model training by combining locally optimized models from various clients into a unified global model. While FL preserves data privacy by eliminating centralized storage, it encounters significant challenges such as performance degradation, slower convergence, and reduced robustness of the global model due to the heterogeneity in client data distributions. Among the v",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks",
      "link": "https://arxiv.org/abs/2502.06684",
      "summary": "arXiv:2502.06684v4 Announce Type: replace-cross \nAbstract: Recent foundational models for tabular data, such as TabPFN, excel at adapting to new tasks via in-context learning, but remain constrained to a fixed, pre-defined number of target dimensions-often necessitating costly ensembling strategies. We trace this constraint to a deeper architectural shortcoming: these models lack target equivariance, so that permuting target dimension orderings alters their predictions. This deficiency gives ris",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code",
      "link": "https://arxiv.org/abs/2502.18851",
      "summary": "arXiv:2502.18851v3 Announce Type: replace-cross \nAbstract: Identifying LLM-generated code through watermarking poses a challenge in preserving functional correctness. Previous methods rely on the assumption that watermarking high-entropy tokens effectively maintains output quality. Our analysis reveals a fundamental limitation of this assumption: syntax-critical tokens such as keywords often exhibit the highest entropy, making existing approaches vulnerable to logic corruption. We present STONE,",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization",
      "link": "https://arxiv.org/abs/2502.20382",
      "summary": "arXiv:2502.20382v2 Announce Type: replace-cross \nAbstract: We present a low-cost data generation pipeline that integrates physics-based simulation, human demonstrations, and model-based planning to efficiently generate large-scale, high-quality datasets for contact-rich robotic manipulation tasks. Starting with a small number of embodiment-flexible human demonstrations collected in a virtual reality simulation environment, the pipeline refines these demonstrations using optimization-based kinema",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Brain-Inspired Exploration of Functional Networks and Key Neurons in Large Language Models",
      "link": "https://arxiv.org/abs/2502.20408",
      "summary": "arXiv:2502.20408v2 Announce Type: replace-cross \nAbstract: In recent years, the rapid advancement of large language models (LLMs) in natural language processing has sparked significant interest among researchers to understand their mechanisms and functional characteristics. Although prior studies have attempted to explain LLM functionalities by identifying and interpreting specific neurons, these efforts mostly focus on individual neuron contributions, neglecting the fact that human brain functi",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Detecting PTSD in Clinical Interviews: A Comparative Analysis of NLP Methods and Large Language Models",
      "link": "https://arxiv.org/abs/2504.01216",
      "summary": "arXiv:2504.01216v3 Announce Type: replace-cross \nAbstract: Post-Traumatic Stress Disorder (PTSD) remains underdiagnosed in clinical settings, presenting opportunities for automated detection to identify patients. This study evaluates natural language processing approaches for detecting PTSD from clinical interview transcripts. We compared general and mental health-specific transformer models (BERT/RoBERTa), embedding-based methods (SentenceBERT/LLaMA), and large language model prompting strategi",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Architecture independent generalization bounds for overparametrized deep ReLU networks",
      "link": "https://arxiv.org/abs/2504.05695",
      "summary": "arXiv:2504.05695v4 Announce Type: replace-cross \nAbstract: We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized d",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Uncertainty-Aware Robotic World Model Makes Offline Model-Based Reinforcement Learning Work on Real Robots",
      "link": "https://arxiv.org/abs/2504.16680",
      "summary": "arXiv:2504.16680v3 Announce Type: replace-cross \nAbstract: Reinforcement Learning (RL) has achieved impressive results in robotics, yet high-performing pipelines remain highly task-specific, with little reuse of prior data. Offline Model-based RL (MBRL) offers greater data efficiency by training policies entirely from existing datasets, but suffers from compounding errors and distribution shift in long-horizon rollouts. Although existing methods have shown success in controlled simulation benchm",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "S2Vec: Self-Supervised Geospatial Embeddings for the Built Environment",
      "link": "https://arxiv.org/abs/2504.16942",
      "summary": "arXiv:2504.16942v2 Announce Type: replace-cross \nAbstract: Scalable general-purpose representations of the built environment are crucial for geospatial artificial intelligence applications. This paper introduces S2Vec, a novel self-supervised framework for learning such geospatial embeddings. S2Vec uses the S2 Geometry library to partition large areas into discrete S2 cells, rasterizes built environment feature vectors within cells as images, and applies masked autoencoding on these rasterized i",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SPD Matrix Learning for Neuroimaging Analysis: Perspectives, Methods, and Challenges",
      "link": "https://arxiv.org/abs/2504.18882",
      "summary": "arXiv:2504.18882v2 Announce Type: replace-cross \nAbstract: Neuroimaging provides essential tools for characterizing brain activity by quantifying connectivity strength between remote regions, using different modalities that capture different aspects of connectivity. Yet, decoding meaningful neural signatures must contend with modality-specific challenges, including measurement noise, spatial and temporal distortions, heterogeneous acquisition protocols, and limited sample sizes. A unifying persp",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "VISTA: Mitigating Semantic Inertia in Video-LLMs via Training-Free Dynamic Chain-of-Thought Routing",
      "link": "https://arxiv.org/abs/2505.11830",
      "summary": "arXiv:2505.11830v3 Announce Type: replace-cross \nAbstract: Recent advancements in Large Language Models have successfully transitioned towards System 2 reasoning, yet applying these paradigms to video understanding remains challenging. While prevailing research attributes failures in Video-LLMs to perceptual limitations, our empirical analysis reveals a cognitive misalignment termed Semantic Inertia, where models suppress valid visual evidence in favor of dominant language priors. To rectify thi",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Social Bias in Popular Question-Answering Benchmarks",
      "link": "https://arxiv.org/abs/2505.15553",
      "summary": "arXiv:2505.15553v3 Announce Type: replace-cross \nAbstract: Question-answering (QA) and reading comprehension (RC) benchmarks are commonly used for assessing the capabilities of large language models (LLMs) to retrieve and reproduce knowledge. However, we demonstrate that popular QA and RC benchmarks do not cover questions about different demographics or regions in a representative way. We perform a content analysis of 30 benchmark papers and a quantitative analysis of 20 respective benchmark dat",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Shared Path: Unraveling Memorization in Multilingual LLMs through Language Similarities",
      "link": "https://arxiv.org/abs/2505.15722",
      "summary": "arXiv:2505.15722v2 Announce Type: replace-cross \nAbstract: We present the first comprehensive study of Memorization in Multilingual Large Language Models (MLLMs), analyzing 95 languages using models across diverse model scales, architectures, and memorization definitions. As MLLMs are increasingly deployed, understanding their memorization behavior has become critical. Yet prior work has focused primarily on monolingual models, leaving multilingual memorization underexplored, despite the inheren",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FinTagging: Benchmarking LLMs for Extracting and Structuring Financial Information",
      "link": "https://arxiv.org/abs/2505.20650",
      "summary": "arXiv:2505.20650v3 Announce Type: replace-cross \nAbstract: Accurate interpretation of numerical data in financial reports is critical for markets and regulators. Although XBRL (eXtensible Business Reporting Language) provides a standard for tagging financial figures, mapping thousands of facts to over ten thousand US-GAAP concepts remains costly and error-prone. Existing benchmarks oversimplify this task as flat, single-step classification over small subsets of concepts, ignoring the hierarchica",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Dissecting Physics Reasoning in Small Language Models: A Multi-Dimensional Analysis from an Educational Perspective",
      "link": "https://arxiv.org/abs/2505.20707",
      "summary": "arXiv:2505.20707v2 Announce Type: replace-cross \nAbstract: Small Language Models (SLMs) offer privacy and efficiency for educational deployment, yet their utility depends on reliable multistep reasoning. Existing benchmarks often prioritize final answer accuracy, obscuring 'right answer, wrong procedure' failures that can reinforce student misconceptions. This work investigates SLM physics reasoning reliability, stage wise failure modes, and robustness under paired contextual variants. We introd",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Reward Is Enough: LLMs Are In-Context Reinforcement Learners",
      "link": "https://arxiv.org/abs/2506.06303",
      "summary": "arXiv:2506.06303v4 Announce Type: replace-cross \nAbstract: Reinforcement learning (RL) is a framework for solving sequential decision-making problems. In this work, we demonstrate that, surprisingly, RL emerges during the inference time of large language models (LLMs), a phenomenon we term in-context RL (ICRL). To reveal this capability, we introduce a simple multi-round prompting framework, we call ICRL prompting, for inference-time self-improvement. The goal of ICRL prompting is to guide LLMs ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Task Matters: Knowledge Requirements Shape LLM Responses to Context-Memory Conflict",
      "link": "https://arxiv.org/abs/2506.06485",
      "summary": "arXiv:2506.06485v3 Announce Type: replace-cross \nAbstract: Large language models (LLMs) draw on both contextual information and parametric memory, yet these sources can conflict. Prior studies have largely examined this issue in contextual question answering, implicitly assuming that tasks should rely on the provided context, leaving unclear how LLMs behave when tasks require different types and degrees of knowledge utilization. We address this gap with a model-agnostic diagnostic framework that",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Improved LLM Agents for Financial Document Question Answering",
      "link": "https://arxiv.org/abs/2506.08726",
      "summary": "arXiv:2506.08726v3 Announce Type: replace-cross \nAbstract: Large language models (LLMs) have shown impressive capabilities on numerous natural language processing tasks. However, LLMs still struggle with numerical question answering for financial documents that include tabular and textual data. Recent works have showed the effectiveness of critic agents (i.e., self-correction) for this task given oracle labels. Building upon this framework, this paper examines the effectiveness of the traditiona",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Uncovering Bias Paths with LLM-guided Causal Discovery: An Active Learning and Dynamic Scoring Approach",
      "link": "https://arxiv.org/abs/2506.12227",
      "summary": "arXiv:2506.12227v2 Announce Type: replace-cross \nAbstract: Ensuring fairness in machine learning requires understanding how sensitive attributes like race or gender causally influence outcomes. Existing causal discovery (CD) methods often struggle to recover fairness-relevant pathways in the presence of noise, confounding, or data corruption. Large language models (LLMs) offer a complementary signal by leveraging semantic priors from variable metadata. We propose a hybrid LLM-guided CD framework",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Machine Learning Model Integration with Open World Temporal Logic for Process Automation",
      "link": "https://arxiv.org/abs/2506.17776",
      "summary": "arXiv:2506.17776v3 Announce Type: replace-cross \nAbstract: Recent advances in Machine Learning (ML) have produced models that extract structured information from complex data. However, a significant challenge lies in translating these perceptual or extractive outputs into actionable and explainable decisions within complex operational workflows. To address these challenges, this paper introduces a novel approach that integrates the outputs of various machine learning models directly with the PyR",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles",
      "link": "https://arxiv.org/abs/2507.07828",
      "summary": "arXiv:2507.07828v2 Announce Type: replace-cross \nAbstract: Content-based puzzle solvers have been extensively studied, demonstrating significant progress in computational techniques. However, their evaluation often lacks realistic challenges crucial for real-world applications, such as the reassembly of fragmented artefacts or shredded documents. In this work, we investigate the robustness of State-Of-The-Art content-based puzzle solvers introducing three types of jigsaw puzzle corruptions: miss",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Low Resource Reconstruction Attacks Through Benign Prompts",
      "link": "https://arxiv.org/abs/2507.07947",
      "summary": "arXiv:2507.07947v3 Announce Type: replace-cross \nAbstract: Recent advances in generative models, such as diffusion models, have raised concerns related to privacy, copyright infringement, and data stewardship. To better understand and control these risks, prior work has introduced techniques and attacks that reconstruct images, or parts of images, from training data. While these results demonstrate that training data can be recovered, existing methods often rely on high computational resources, ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Invisible Leash: Why RLVR May or May Not Escape Its Origin",
      "link": "https://arxiv.org/abs/2507.14843",
      "summary": "arXiv:2507.14843v3 Announce Type: replace-cross \nAbstract: Recent advances in LLMs highlight Reinforcement Learning with Verifiable Rewards (RLVR) as a promising method for enhancing AI capabilities, particularly in solving complex logical tasks. However, it remains unclear whether the current practice of RLVR truly expands a model's reasoning boundary or mainly amplifies high-reward outputs that the base model already knows, leading to improved precision. This study presents an empirical invest",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CNN-based Surface Temperature Forecasts with Ensemble Numerical Weather Prediction over Medium-range Forecast Periods",
      "link": "https://arxiv.org/abs/2507.18937",
      "summary": "arXiv:2507.18937v2 Announce Type: replace-cross \nAbstract: In this study, a method that integrates convolutional neural networks (CNNs) with ensemble numerical weather prediction (NWP) models is proposed. This method enables surface temperature forecasting with lead times beyond the short-range, extending up to five days. Due to limited computational resources, operational medium-range temperature forecasts typically rely on low-resolution NWP models, which are prone to systematic and random err",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LAG: Logic-Augmented Generation from a Cartesian Perspective",
      "link": "https://arxiv.org/abs/2508.05509",
      "summary": "arXiv:2508.05509v3 Announce Type: replace-cross \nAbstract: Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet exhibit critical limitations in knowledge-intensive tasks, often generating hallucinations when faced with questions requiring specialized expertise. While retrieval-augmented generation (RAG) mitigates this by integrating external knowledge, it struggles with complex reasoning scenarios due to its reliance on direct semantic retrieva",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Neural Network Quantization for Microcontrollers: A Comprehensive Survey of Methods, Platforms, and Applications",
      "link": "https://arxiv.org/abs/2508.15008",
      "summary": "arXiv:2508.15008v4 Announce Type: replace-cross \nAbstract: The deployment of Quantized Neural Networks (QNNs) on resource-constrained edge devices, such as microcontrollers (MCUs), introduces fundamental challenges in balancing model performance, computational complexity, and memory constraints. Tiny Machine Learning (TinyML) addresses these issues by jointly advancing machine learning algorithms, hardware architectures, and software optimization techniques to enable deep neural network inferenc",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Task-Stratified Knowledge Scaling Laws for Post-Training Quantized Large Language Models",
      "link": "https://arxiv.org/abs/2508.18609",
      "summary": "arXiv:2508.18609v3 Announce Type: replace-cross \nAbstract: Post-Training Quantization (PTQ) is a critical strategy for efficient Large Language Models (LLMs) deployment. However, existing scaling laws primarily focus on general performance, overlooking crucial fine-grained factors and how quantization differentially impacts diverse knowledge capabilities. To address this, we establish Task-Stratified Knowledge Scaling Laws. By stratifying capabilities into memorization, application, and reasonin",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation",
      "link": "https://arxiv.org/abs/2508.19614",
      "summary": "arXiv:2508.19614v3 Announce Type: replace-cross \nAbstract: Retrieval-augmented generation (RAG) incorporates external knowledge into large language models (LLMs), improving their adaptability to downstream tasks and enabling information updates. Surprisingly, recent empirical evidence demonstrates that injecting noise into retrieved relevant documents paradoxically facilitates exploitation of external knowledge and improves generation quality. Although counterintuitive and challenging to apply i",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems",
      "link": "https://arxiv.org/abs/2508.21296",
      "summary": "arXiv:2508.21296v2 Announce Type: replace-cross \nAbstract: Continual or Lifelong Learning aims to develop models capable of acquiring new knowledge from a sequence of tasks without catastrophically forgetting what has been learned before. Existing approaches often rely on storing samples from previous tasks (experience replay) or employing complex regularization terms to protect learned weights. However, these methods face challenges related to data privacy, storage limitations, and performance ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Web Fraud Attacks Against LLM-Driven Multi-Agent Systems",
      "link": "https://arxiv.org/abs/2509.01211",
      "summary": "arXiv:2509.01211v2 Announce Type: replace-cross \nAbstract: With the proliferation of LLM-driven multi-agent systems (MAS), the security of Web links has become a critical concern. Once MAS is induced to trust a malicious link, attackers can use it as a springboard to expand the attack surface. In this paper, we propose Web Fraud Attacks, a novel type of attack manipulating unique structures of web links to deceive MAS. We design 12 representative attack variants that encompass various methods, s",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving",
      "link": "https://arxiv.org/abs/2509.08269",
      "summary": "arXiv:2509.08269v4 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) possess substantial reasoning capabilities and are increasingly applied to optimization tasks, particularly in synergy with evolutionary computation. However, while recent surveys have explored specific aspects of this domain, they lack an integrative perspective that connects problem modeling with solving workflows. To address this gap, we present a systematic review of recent developments and organize them ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning",
      "link": "https://arxiv.org/abs/2509.14803",
      "summary": "arXiv:2509.14803v4 Announce Type: replace-cross \nAbstract: In online learning environments, students often lack personalized peer interactions, which are crucial for cognitive development and learning engagement. Although previous studies have employed large language models (LLMs) to simulate interactive learning environments, these interactions are limited to conversational exchanges, failing to adapt to learners' individualized cognitive and psychological states. As a result, students' engagem",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Relevance to Utility: Process-Supervised Rewrite for RAG",
      "link": "https://arxiv.org/abs/2509.15577",
      "summary": "arXiv:2509.15577v2 Announce Type: replace-cross \nAbstract: Retrieval-augmented generation systems often suffer from a gap between optimizing retrieval relevance and generative utility. With such a gap, retrieved documents may be topically relevant but still lack the content needed for effective reasoning during generation. While existing bridge modules attempt to rewrite the retrieved text for better generation, we show how they fail by not capturing \"document utility\". In this work, we propose ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "DyBBT: Dynamic Balance via Bandit inspired Targeting for Dialog Policy with Cognitive Dual-Systems",
      "link": "https://arxiv.org/abs/2509.19695",
      "summary": "arXiv:2509.19695v2 Announce Type: replace-cross \nAbstract: Task oriented dialog systems often rely on static exploration strategies that do not adapt to dynamic dialog contexts, leading to inefficient exploration and suboptimal performance. We propose DyBBT, a novel dialog policy learning framework that formalizes the exploration challenge through a structured cognitive state space capturing dialog progression, user uncertainty, and slot dependency. DyBBT proposes a bandit inspired meta-controll",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST",
      "link": "https://arxiv.org/abs/2509.19742",
      "summary": "arXiv:2509.19742v3 Announce Type: replace-cross \nAbstract: Zero-shot Dialog State Tracking (zs-DST) is essential for enabling Task-Oriented Dialog Systems (TODs) to generalize to new domains without costly data annotation. A central challenge lies in the semantic misalignment between dynamic dialog contexts and static prompts, leading to inflexible cross-layer coordination, domain interference, and catastrophic forgetting. To tackle this, we propose Hierarchical Collaborative Low-Rank Adaptation",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CaTS-Bench: Can Language Models Describe Time Series?",
      "link": "https://arxiv.org/abs/2509.20823",
      "summary": "arXiv:2509.20823v3 Announce Type: replace-cross \nAbstract: Time series captioning, the task of describing time series in natural language, requires numeric and temporal reasoning, trend interpretation, and contextual understanding. Existing benchmarks, however, often rely on fully synthetic or generic captions, and typically neglect metadata and visual representations. We introduce \\textbf{CaTS-Bench}, a comprehensive benchmark for \\textbf{C}ontext-\\textbf{a}ware \\textbf{T}ime \\textbf{S}eries re",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "How Training Data Shapes the Use of Parametric and In-Context Knowledge in Language Models",
      "link": "https://arxiv.org/abs/2510.02370",
      "summary": "arXiv:2510.02370v2 Announce Type: replace-cross \nAbstract: Large language models leverage not only parametric knowledge acquired during training but also in-context knowledge provided at inference time, despite the absence of explicit training objectives for using both sources. Prior work has further shown that when these knowledge sources conflict, models resolve the tension based on their internal confidence, preferring parametric knowledge for high-confidence facts while deferring to contextu",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AI-Driven Grading and Moderation for Collaborative Projects in Computer Science Education",
      "link": "https://arxiv.org/abs/2510.03998",
      "summary": "arXiv:2510.03998v2 Announce Type: replace-cross \nAbstract: Collaborative group projects are integral to computer science education, as they foster teamwork, problem-solving skills, and industry-relevant competencies. However, assessing individual contributions in group settings has long been challenging. Traditional assessment strategies, such as the equal distribution of grades or subjective peer assessments, often fall short in terms of fairness, objectivity, and scalability, particularly in l",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Hybrid Computational Intelligence Framework with Metaheuristic Optimization for Drug-Drug Interaction Prediction",
      "link": "https://arxiv.org/abs/2510.09668",
      "summary": "arXiv:2510.09668v2 Announce Type: replace-cross \nAbstract: Drug-drug interactions (DDIs) are a leading cause of preventable adverse events, often complicating treatment and increasing healthcare costs. At the same time, knowing which drugs do not interact is equally important, as such knowledge supports safer prescriptions and better patient outcomes. In this study, we propose an interpretable and efficient framework that blends modern machine learning with domain knowledge to improve DDI predic",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Big Reasoning with Small Models: Instruction Retrieval at Inference Time",
      "link": "https://arxiv.org/abs/2510.13935",
      "summary": "arXiv:2510.13935v2 Announce Type: replace-cross \nAbstract: Small language models (SLMs) enable low-cost, private, on-device inference, but they often fail on problems that require specialized domain knowledge or multi-step reasoning. Existing approaches for improving reasoning either rely on scale (e.g., chain-of-thought prompting), require task-specific training that limits reuse and generality (e.g., distillation), or retrieve unstructured information that still leaves the SLM to determine an ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning",
      "link": "https://arxiv.org/abs/2510.14211",
      "summary": "arXiv:2510.14211v2 Announce Type: replace-cross \nAbstract: Multi-stage reasoning has emerged as an effective strategy for enhancing the reasoning capability of small language models by decomposing complex problems into sequential sub-stages. However, this comes at the cost of increased latency. We observe that existing adaptive acceleration techniques, such as layer skipping, struggle to balance efficiency and accuracy in this setting due to two key challenges: (1) stage-wise variation in skip s",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "L-MoE: End-to-End Training of a Lightweight Mixture of Low-Rank Adaptation Experts",
      "link": "https://arxiv.org/abs/2510.17898",
      "summary": "arXiv:2510.17898v2 Announce Type: replace-cross \nAbstract: The Mixture of Experts (MoE) architecture enables the scaling of Large Language Models (LLMs) to trillions of parameters by activating a sparse subset of weights for each input, maintaining constant computational cost during inference. Concurrently, Low-Rank Adaptation (LoRA) has emerged as a dominant technique for parameter-efficiently fine-tuning LLMs on specialized tasks. In this work, we unify these two paradigms into a novel, end-to",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios",
      "link": "https://arxiv.org/abs/2510.20721",
      "summary": "arXiv:2510.20721v2 Announce Type: replace-cross \nAbstract: Large language models (LLMs) are rapidly being adopted for tasks like drafting emails, summarizing meetings, and answering health questions. In these settings, users may need to share private information (e.g., contact details, health records). To evaluate LLMs' ability to identify and redact such information, prior work introduced real-life, scenario-based benchmarks (e.g., ConfAIde, PrivacyLens) and found that LLMs can leak private inf",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Beyond Direct Generation: A Decomposed Approach to Well-Crafted Screenwriting with LLMs",
      "link": "https://arxiv.org/abs/2510.23163",
      "summary": "arXiv:2510.23163v3 Announce Type: replace-cross \nAbstract: The screenplay serves as the foundation for television production, defining narrative structure, character development, and dialogue. While Large Language Models (LLMs) show great potential in creative writing, direct end-to-end generation approaches often fail to produce well-crafted screenplays. We argue this failure stems from forcing a single model to simultaneously master two disparate capabilities: creative narrative construction a",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Computational Foundations for Strategic Coopetition: Formalizing Trust and Reputation Dynamics",
      "link": "https://arxiv.org/abs/2510.24909",
      "summary": "arXiv:2510.24909v2 Announce Type: replace-cross \nAbstract: Modern socio-technical systems increasingly involve multi-stakeholder environments where actors simultaneously cooperate and compete. These coopetitive relationships exhibit dynamic trust evolution based on observed behavior over repeated interactions. While conceptual modeling languages like i* represent trust relationships qualitatively, they lack computational mechanisms for analyzing how trust changes with behavioral evidence. Conver",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail",
      "link": "https://arxiv.org/abs/2511.00088",
      "summary": "arXiv:2511.00088v2 Announce Type: replace-cross \nAbstract: End-to-end architectures trained via imitation learning have advanced autonomous driving by scaling model size and data, yet performance remains brittle in safety-critical long-tail scenarios where supervision is sparse and causal understanding is limited. We introduce Alpamayo-R1 (AR1), a vision-language-action model (VLA) that integrates Chain of Causation reasoning with trajectory planning for complex driving scenarios. Our approach f",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "EngTrace: A Symbolic Benchmark for Verifiable Process Supervision of Engineering Reasoning",
      "link": "https://arxiv.org/abs/2511.01650",
      "summary": "arXiv:2511.01650v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) are increasingly entering specialized, safety-critical engineering workflows governed by strict quantitative standards and immutable physical laws, making rigorous evaluation of their reasoning capabilities imperative. However, existing benchmarks such as MMLU, MATH, and HumanEval assess isolated cognitive skills, failing to capture the physically grounded reasoning central to engineering, where scientific pr",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention",
      "link": "https://arxiv.org/abs/2511.06294",
      "summary": "arXiv:2511.06294v3 Announce Type: replace-cross \nAbstract: Recent advances in Transformer-based Neural Operators have enabled significant progress in data-driven solvers for Partial Differential Equations (PDEs). Most current research has focused on reducing the quadratic complexity of attention to address the resulting low training and inference efficiency. Among these works, Transolver stands out as a representative method that introduces Physics-Attention to reduce computational costs. Physic",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Enabling Agents to Communicate Entirely in Latent Space",
      "link": "https://arxiv.org/abs/2511.09149",
      "summary": "arXiv:2511.09149v2 Announce Type: replace-cross \nAbstract: While natural language is the de facto communication medium for LLM-based agents, it presents a fundamental constraint. The process of downsampling rich, internal latent states into discrete tokens inherently limits the depth and nuance of information that can be transmitted, thereby hindering collaborative problem-solving. Inspired by telepathy, which bypasses symbolic language in communication, we propose Interlat (Inter-agent Latent S",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation",
      "link": "https://arxiv.org/abs/2511.12631",
      "summary": "arXiv:2511.12631v2 Announce Type: replace-cross \nAbstract: While significant progress has been achieved in multimodal facial generation using semantic masks and textual descriptions, conventional feature fusion approaches often fail to enable effective cross-modal interactions, thereby leading to suboptimal generation outcomes. To address this challenge, we introduce MDiTFace--a customized diffusion transformer framework that employs a unified tokenization strategy to process semantic mask and t",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CausalProfiler: Generating Synthetic Benchmarks for Rigorous and Transparent Evaluation of Causal Machine Learning",
      "link": "https://arxiv.org/abs/2511.22842",
      "summary": "arXiv:2511.22842v2 Announce Type: replace-cross \nAbstract: Causal machine learning (Causal ML) aims to answer \"what if\" questions using machine learning algorithms, making it a promising tool for high-stakes decision-making. Yet, empirical evaluation practices in Causal ML remain limited. Existing benchmarks often rely on a handful of hand-crafted or semi-synthetic datasets, leading to brittle, non-generalizable conclusions. To bridge this gap, we introduce CausalProfiler, a synthetic benchmark ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Table as a Modality for Large Language Models",
      "link": "https://arxiv.org/abs/2512.00947",
      "summary": "arXiv:2512.00947v2 Announce Type: replace-cross \nAbstract: To migrate the remarkable successes of Large Language Models (LLMs), the community has made numerous efforts to generalize them to the table reasoning tasks for the widely deployed tabular data. Despite that, in this work, by showing a probing experiment on our proposed StructQA benchmark, we postulate that even the most advanced LLMs (such as GPTs) may still fall short of coping with tabular data. More specifically, the current scheme o",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding",
      "link": "https://arxiv.org/abs/2512.07344",
      "summary": "arXiv:2512.07344v2 Announce Type: replace-cross \nAbstract: Vision-language models (VLMs) have demonstrated impressive multimodal comprehension capabilities and are being deployed in an increasing number of online video understanding applications. While recent efforts extensively explore advancing VLMs' reasoning power in these cases, deployment constraints are overlooked, leading to overwhelming system overhead in real-world deployments. To address that, we propose Venus, an on-device memory-and",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SWAA: Sliding Window Attention Adaptation for Efficient Long-Context LLMs Without Pretraining",
      "link": "https://arxiv.org/abs/2512.10411",
      "summary": "arXiv:2512.10411v4 Announce Type: replace-cross \nAbstract: The quadratic complexity of self-attention in Transformer-based Large Language Models (LLMs) renders long-context inference prohibitively expensive. While Sliding Window Attention (SWA), the simplest sparse attention pattern, offers a linear-complexity alternative, naively applying it to models pretrained with Full Attention (FA) causes catastrophic long-context performance collapse due to the training-inference mismatch. To address this",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring",
      "link": "https://arxiv.org/abs/2512.12069",
      "summary": "arXiv:2512.12069v2 Announce Type: replace-cross \nAbstract: Large Vision-Language Models (LVLMs) are vulnerable to a growing array of multimodal jailbreak attacks, necessitating defenses that are both generalizable to novel threats and efficient for practical deployment. Many current strategies fall short, either targeting specific attack patterns, which limits generalization, or imposing high computational overhead. While lightweight anomaly-detection methods offer a promising direction, we find",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Improving Underwater Acoustic Classification Through Learnable Gabor Filter Convolution and Attention Mechanisms",
      "link": "https://arxiv.org/abs/2512.14714",
      "summary": "arXiv:2512.14714v2 Announce Type: replace-cross \nAbstract: Remotely detecting and classifying underwater acoustic targets is critical for environmental monitoring and defence. However, the complexity of ship-radiated and environmental noise poses significant challenges for accurate signal processing. While recent advancements in machine learning have improved classification accuracy, limited dataset availability and a lack of standardised experimentation hinder generalisation and robustness. Thi",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "V-Agent: An Interactive Video Search System Using Vision-Language Models",
      "link": "https://arxiv.org/abs/2512.16925",
      "summary": "arXiv:2512.16925v2 Announce Type: replace-cross \nAbstract: We introduce V-Agent, a novel multi-agent platform designed for advanced video search and interactive user-system conversations. By fine-tuning a vision-language model (VLM) with a small video preference dataset and enhancing it with a retrieval vector from an image-text retrieval model, we overcome the limitations of traditional text-based retrieval systems in multimodal scenarios. The VLM-based retrieval model independently embeds vide",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Formal Descriptive Language for Learning Dynamics: A Five-Layer Structural Coordinate System",
      "link": "https://arxiv.org/abs/2512.18525",
      "summary": "arXiv:2512.18525v2 Announce Type: replace-cross \nAbstract: Understanding learning as a dynamic process is challenging due to the interaction of multiple factors, including cognitive load, internal state change, and subjective evaluation. Existing approaches often address these elements in isolation, limiting the ability to describe learning phenomena within a unified and structurally explicit framework. This paper proposes a multi-layer formal descriptive framework for learning dynamics. Rather ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "VULCAN: Tool-Augmented Multi Agents for Iterative 3D Object Arrangement",
      "link": "https://arxiv.org/abs/2512.22351",
      "summary": "arXiv:2512.22351v2 Announce Type: replace-cross \nAbstract: Despite the remarkable progress of Multimodal Large Language Models (MLLMs) in 2D vision-language tasks, their application to complex 3D scene manipulation remains underexplored. In this paper, we bridge this critical gap by tackling three key challenges in 3D object arrangement task using MLLMs. First, to address the weak visual grounding of MLLMs, which struggle to link programmatic edits with precise 3D outcomes, we introduce an MCP-b",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "When in Doubt, Consult: Expert Debate for Sexism Detection via Confidence-Based Routing",
      "link": "https://arxiv.org/abs/2512.23732",
      "summary": "arXiv:2512.23732v3 Announce Type: replace-cross \nAbstract: Online sexism increasingly appears in subtle, context-dependent forms that evade traditional detection methods. Its interpretation often depends on overlapping linguistic, psychological, legal, and cultural dimensions, which produce mixed and sometimes contradictory signals in annotated datasets. These inconsistencies, combined with label scarcity and class imbalance, result in unstable decision boundaries and cause fine-tuned models to ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Impact of LLMs on Online News Consumption and Production",
      "link": "https://arxiv.org/abs/2512.24968",
      "summary": "arXiv:2512.24968v2 Announce Type: replace-cross \nAbstract: Large language models (LLMs) change how consumers acquire information online; their bots also crawl news publishers' websites for training data and to answer consumer queries; and they provide tools that can lower the cost of content creation. These changes lead to predictions of adverse impact on news publishers in the form of lowered consumer demand, reduced demand for newsroom employees, and an increase in news \"slop.\" Consequently, s",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds",
      "link": "https://arxiv.org/abs/2601.00834",
      "summary": "arXiv:2601.00834v2 Announce Type: replace-cross \nAbstract: Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly i",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Attention Needs to Focus: A Unified Perspective on Attention Allocation",
      "link": "https://arxiv.org/abs/2601.00919",
      "summary": "arXiv:2601.00919v2 Announce Type: replace-cross \nAbstract: The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring thei",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Wittgenstein's Family Resemblance Clustering Algorithm",
      "link": "https://arxiv.org/abs/2601.01127",
      "summary": "arXiv:2601.01127v2 Announce Type: replace-cross \nAbstract: This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms ",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory",
      "link": "https://arxiv.org/abs/2601.01280",
      "summary": "arXiv:2601.01280v2 Announce Type: replace-cross \nAbstract: Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this fr",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems",
      "link": "https://arxiv.org/abs/2601.01410",
      "summary": "arXiv:2601.01410v3 Announce Type: replace-cross \nAbstract: Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics mask this operational asymmetry. We introduce a grid-specific evaluation framework (Asymmetric MAPE, Under-Prediction Rate, and Reserve Margin) that directly measures operational risk rather than statistical accuracy alone. Using this framework, we conduct a systematic evaluation of Mamba-based State Space Models for",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation",
      "link": "https://arxiv.org/abs/2601.01513",
      "summary": "arXiv:2601.01513v2 Announce Type: replace-cross \nAbstract: Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a light",
      "published": "2026-01-09T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    }
  ]
}